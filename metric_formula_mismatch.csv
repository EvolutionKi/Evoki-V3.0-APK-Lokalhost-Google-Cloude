metric_id,file,func,params,comp_upstream,comp_formula,missing_in_upstream,missing_in_formula
m101_t_panic,C:\Evoki V3.0 APK-Lokalhost-Google Cloude\backend\core\evoki_metrics_v3\metrics_lib_v12_clean\m101_t_panic.py,compute_m101_t_panic,text,"text, panic_lexikon","t_panic = clip( Σ(panic_lex_hit × weight) / (text_len + ε) × scale ) wobei: panic_lex_hit = 1 wenn Wort im Panik-Lexikon gefunden weight = Gewichtung aus Lexikon (1.0-3.0) text_len = Anzahl Wörter im Text ε = 1 (verhindert Division durch 0) scale = 10.0 (Skalierungsfaktor) clip = Begrenzung auf [0, 1]",,
m102_t_disso,C:\Evoki V3.0 APK-Lokalhost-Google Cloude\backend\core\evoki_metrics_v3\metrics_lib_v12_clean\m102_t_disso.py,compute_m102_t_disso,text,"text, disso_lexikon",t_disso = clip( Σ(disso_lex_hit × weight) / (text_len + ε) × scale ) wobei: disso_lex_hit = 1 wenn Wort im Dissoziations-Lexikon weight = Gewichtung (1.0-2.5) scale = 8.0,,
m103_t_integ,C:\Evoki V3.0 APK-Lokalhost-Google Cloude\backend\core\evoki_metrics_v3\metrics_lib_v12_clean\m103_t_integ.py,compute_m103_t_integ,text,"text, integ_lexikon",t_integ = clip( Σ(integ_lex_hit × weight) / (text_len + ε) × scale ),,
m110_black_hole,C:\Evoki V3.0 APK-Lokalhost-Google Cloude\backend\core\evoki_metrics_v3\metrics_lib_v12_clean\m110_black_hole.py,compute_m110_black_hole,"chaos,effective_A,LL","t_disso, chaos, z_prox","# Schema A (Turbidity): turb_2 = t_disso × chaos × z_prox # Schema B (Black Hole - V3.3.3 CONTEXT-AWARE): base = 0.4 × chaos + 0.3 × (1 - A) + 0.3 × LL # Context-Aware Veto (Lexikon = Ankläger, LLM = Richter): IF panic_hits >= 2: is_real_emergency = semantic_guardian.check_urgency(text) IF is_real_emergency: black_hole = max(base, 0.85)  # Bestätigter Notfall ELSE: black_hole = base + 0.1       # Nur leichter Malus für neg. Wortwahl ELSE: black_hole = base","effective_A,LL",effective_A
m111_turbidity_total,C:\Evoki V3.0 APK-Lokalhost-Google Cloude\backend\core\evoki_metrics_v3\metrics_lib_v12_clean\m111_turbidity_total.py,compute_m111_turbidity_total,"t_panic,t_disso,t_shock,t_integ",,,"t_panic,t_disso,t_shock,t_integ","t_panic,t_disso,t_shock,t_integ"
m112_trauma_load,C:\Evoki V3.0 APK-Lokalhost-Google Cloude\backend\core\evoki_metrics_v3\metrics_lib_v12_clean\m112_trauma_load.py,compute_m112_trauma_load,"t_panic,t_disso,t_integ",,,"t_panic,t_disso,t_integ","t_panic,t_disso,t_integ"
m114_t_recovery,C:\Evoki V3.0 APK-Lokalhost-Google Cloude\backend\core\evoki_metrics_v3\metrics_lib_v12_clean\m114_t_recovery.py,compute_m114_t_recovery,"t_integ_current,t_integ_prev",,,"t_integ_current,t_integ_prev","t_integ_current,t_integ_prev"
m144_sys_stability,C:\Evoki V3.0 APK-Lokalhost-Google Cloude\backend\core\evoki_metrics_v3\metrics_lib_v12_clean\m144_sys_stability.py,compute_m144_sys_stability,"error_rate,latency_norm",,,"error_rate,latency_norm","error_rate,latency_norm"
m151_omega,C:\Evoki V3.0 APK-Lokalhost-Google Cloude\backend\core\evoki_metrics_v3\metrics_lib_v12_clean\m151_omega.py,compute_m151_omega,"A,PCI,z_prox,trauma_load","phi, rule_conflict","# V3.0.2 FIX: Subtraktive Logik behebt Paradoxon bei negativem Phi # ALT (fehlerhaft): Omega = Phi × (1 - conflict) # Problem: Bei Phi=-0.8, conflict=0.9 ist -0.08 > -0.8 (Regelbruch wird belohnt!) Omega = Phi - (rule_conflict × 1.5) Omega = clip(Omega, -1.0, 1.0)","A,PCI,z_prox,trauma_load","PCI,z_prox,trauma_load"
m153_sys_health,C:\Evoki V3.0 APK-Lokalhost-Google Cloude\backend\core\evoki_metrics_v3\metrics_lib_v12_clean\m153_sys_health.py,compute_m153_sys_health,"latency,error_rate,mem_pressure",,,"latency,error_rate,mem_pressure","latency,error_rate,mem_pressure"
m161_commit,C:\Evoki V3.0 APK-Lokalhost-Google Cloude\backend\core\evoki_metrics_v3\metrics_lib_v12_clean\m161_commit.py,compute_m161_commit,"z_prox,trauma_load",,,"z_prox,trauma_load","z_prox,trauma_load"
m17_nabla_a,C:\Evoki V3.0 APK-Lokalhost-Google Cloude\backend\core\evoki_metrics_v3\metrics_lib_v12_clean\m17_nabla_a.py,compute_m17_nabla_a,"a_current,a_previous",,∇A = A_current - A_previous,"a_current,a_previous","a_current,a_previous"
m18_s_entropy,C:\Evoki V3.0 APK-Lokalhost-Google Cloude\backend\core\evoki_metrics_v3\metrics_lib_v12_clean\m18_s_entropy.py,compute_m18_s_entropy,tokens,text,H = -Σ p(token_i) × log₂(p(token_i)) wobei: p(token_i) = count(token_i) / total_tokens Summe über alle unique tokens,tokens,
m19_z_prox,C:\Evoki V3.0 APK-Lokalhost-Google Cloude\backend\core\evoki_metrics_v3\metrics_lib_v12_clean\m19_z_prox.py,compute_m19_z_prox,"m1_A_lexical,m15_A_structural,LL,text,t_panic",,"# ALTE Formel (vor V3.0.3): # z_prox = (1 - A) × LL # V3.0.3 Safety-First + V3.3.2 Hazard Bonus: effective_A = min(m1_A_lexical, m15_A_structural) base_prox = (1 - effective_A) × LL # Hazard Bonus: Lexikon-Treffer verstärken das Risiko z_prox = min(1.0, base_prox × (1 + hazard_bonus)) wobei: m1_A = Lexikon-basierter Affekt m15_A = Strukturell berechneter Affekt LL = Lambert-Light (Trübung) hazard_bonus = Summe der Lexikon-Hazard-Scores (0.0-0.5) Worst case: effective_A=0, LL=1, hazard=0.5 → z_prox=1.0","m1_A_lexical,m15_A_structural,LL,text,t_panic","text,t_panic"
m1_A,C:\Evoki V3.0 APK-Lokalhost-Google Cloude\backend\core\evoki_metrics_v3\metrics_lib_v12_clean\m1_A.py,compute_m1_A,"coh,flow,LL,ZLF,ctx_break",,"A = base_score × (1 + lex_boost) × stability_factor wobei: base_score = f(word_count, sentence_complexity, semantic_density) lex_boost = Σ(lexikon_treffer_i × gewicht_i) / text_len stability_factor = 1 / (1 + abs(nabla_a_prev)) Normalisierung: A ∈ [0, 1]","coh,flow,LL,ZLF,ctx_break","coh,flow,LL,ZLF,ctx_break"
m22_cog_load,C:\Evoki V3.0 APK-Lokalhost-Google Cloude\backend\core\evoki_metrics_v3\metrics_lib_v12_clean\m22_cog_load.py,compute_m22_cog_load,token_count,token_count,cog_load = clip( token_count / 500.0 ),,
m23_nabla_pci,C:\Evoki V3.0 APK-Lokalhost-Google Cloude\backend\core\evoki_metrics_v3\metrics_lib_v12_clean\m23_nabla_pci.py,compute_m23_nabla_pci,"pci_current,pci_previous","pci_current, pci_previous",∇PCI = PCI_current - PCI_previous,,"pci_current,pci_previous"
m2_PCI,C:\Evoki V3.0 APK-Lokalhost-Google Cloude\backend\core\evoki_metrics_v3\metrics_lib_v12_clean\m2_PCI.py,compute_m2_PCI,"flow,coh,LL",,"PCI = α × unique_ratio + β × complexity + γ × integration wobei: unique_ratio = |unique_words| / |total_words| complexity = avg_sentence_length / reference_length integration = |context_overlap| / |current_words| α = 0.5, β = 0.3, γ = 0.2  (Gewichte) Normalisierung: PCI ∈ [0, 1]","flow,coh,LL","flow,coh,LL"
m36_rule_conflict,C:\Evoki V3.0 APK-Lokalhost-Google Cloude\backend\core\evoki_metrics_v3\metrics_lib_v12_clean\m36_rule_conflict.py,compute_m36_rule_conflict,rules,,rule_conflict = clip( 0.5×LL + 0.3×(1-coh) + 0.2×ctx_break ),rules,rules
m37_rule_stable,C:\Evoki V3.0 APK-Lokalhost-Google Cloude\backend\core\evoki_metrics_v3\metrics_lib_v12_clean\m37_rule_stable.py,compute_m37_rule_stable,rule_conflict,rule_conflict,rule_stable = 1.0 - rule_conflict,,
m38_soul_integrity,C:\Evoki V3.0 APK-Lokalhost-Google Cloude\backend\core\evoki_metrics_v3\metrics_lib_v12_clean\m38_soul_integrity.py,compute_m38_soul_integrity,b_vector,"rule_stable, A",soul_integrity = rule_stable × A wobei: rule_stable = m37_rule_stable A = Affekt Score,b_vector,b_vector
m39_soul_check,C:\Evoki V3.0 APK-Lokalhost-Google Cloude\backend\core\evoki_metrics_v3\metrics_lib_v12_clean\m39_soul_check.py,compute_m39_soul_check,"b_vector,seed","soul_integrity, A",soul_check = soul_integrity × A,"b_vector,seed","b_vector,seed"
m6_ZLF,C:\Evoki V3.0 APK-Lokalhost-Google Cloude\backend\core\evoki_metrics_v3\metrics_lib_v12_clean\m6_ZLF.py,compute_m6_ZLF,"flow,coherence,zlf_lexicon_hit",,"ZLF = clip( 0.5 × (1 - flow) + 0.5 × (1 - coherence) ) wobei: flow = m4_flow (Flow State - exponentieller Zeitverzerrungsfaktor) coherence = m5_coh (Kohärenz - Jaccard-Ähnlichkeit mit History) clip = Normalisierung auf [0, 1]","flow,coherence,zlf_lexicon_hit",zlf_lexicon_hit
m7_LL,C:\Evoki V3.0 APK-Lokalhost-Google Cloude\backend\core\evoki_metrics_v3\metrics_lib_v12_clean\m7_LL.py,compute_m7_LL,"rep_same,flow,coh",,LL = clip(0.55*rep_same + 0.25*(1-flow) + 0.20*(1-coh)),"rep_same,flow,coh",
