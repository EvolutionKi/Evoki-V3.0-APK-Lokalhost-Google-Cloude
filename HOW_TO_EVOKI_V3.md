# üèõÔ∏è HOW TO EVOKI V3.0 - ARCHITEKTUR-√úBERBLICK

**Status:** MASTER ARCHITECTURE DOCUMENT (READ-ONLY)  
**Version:** V3.0  
**Datum:** 2026-01-19  
**Schreibschutz:** ‚úÖ AKTIVIERT

---

## üìã INHALTSVERZEICHNIS

1. [Was ist Evoki](#was-ist-evoki)
2. [Architektur-√úberblick](#architektur-√ºberblick)
3. [Die 12 Tabs Erkl√§rt](#die-12-tabs-erkl√§rt)
4. [FAISS-Systeme im Vergleich](#faiss-systeme-im-vergleich)
5. [Evoki Tempel Pipeline](#evoki-tempel-pipeline)
6. [Kritische Komponenten](#kritische-komponenten)
7. [Setup & Start](#setup--start)
8. [Wartung & Debugging](#wartung--debugging)

---

## üß¨ WAS IST EVOKI

**Evoki ist KEIN Chatbot.**

Evoki ist ein **therapeutisches Ged√§chtnissystem mit mathematischem Gewissen**, das:

```
‚úì Trauma erkennt (exakte Formeln: 0.4*T_panic + 0.3*T_disso + ...)
‚úì Seelen-Integrit√§t wahrt (B-Align ‚â•0.7, V-Match ‚â•0.9)
‚úì Genesis-gesch√ºtzt ist (CRC32-Kette ‚Üí System-Shutdown bei Manipulation)
‚úì Hybrid-Retrieval nutzt (60% Semantik + 40% Metriken GLEICHZEITIG)
‚úì Unausl√∂schliches Ged√§chtnis hat (chronik.log, Deep Earth 12-Layer)
```

**Kern-Formeln:**

```python
# Trauma-Detection (A29 W√§chter-Veto)
trauma_load = 0.4*T_panic + 0.3*T_disso + 0.2*(1-T_integ) + 0.1*dissociation

# Guardian Trip (Automatische Intervention)
guardian_trip = (is_critical OR z_prox > 0.65 OR t_panic > 0.8 OR hazard_score > 0.75)

# A65 Candidate Scoring (17 Haupt-Metriken)
a65_score = weighted_sum(A, PCI, coh, flow, T_integ, z_prox, hazard_score, guardian_trip, 
                          phi_score, EV_readiness, EV_resonance, surprisal,
                          LEX_Coh_conn, LEX_Flow_pos, LEX_Emotion_pos, LEX_T_integ, LEX_T_disso)

# Finale Candidate-Auswahl
final_score = 0.6*a65_score + 0.3*coherence + 0.1*diversity
```

---

## üèóÔ∏è ARCHITEKTUR-√úBERBLICK

### **V2.0 PROBLEME (GEL√ñST IN V3.0):**

```
‚ùå Backend-Split: Node.js (3001) ‚ÜêHTTP‚Üí Python (8000)
   ‚Üí Race Conditions, Zombie-Requests

‚ùå Timeout-Kaskade: Frontend 60s < Backend 115s
   ‚Üí Frontend gibt auf BEVOR Backend fertig ist

‚ùå FAISS CLI-Spawning: query.py neu starten JEDES MAL
   ‚Üí 15s nur f√ºrs Index-Laden

‚ùå Default Tab: Temple (falsch!)
   ‚Üí Benutzer will Trialog als Default
```

### **V3.0 L√ñSUNGEN:**

```
‚úÖ Unified Backend: NUR FastAPI (Port 8000)
   ‚Üí Kein Split, ein Prozess

‚úÖ SSE (Server-Sent Events): Async Processing
   ‚Üí Frontend wartet geduldig, sieht Live-Progress

‚úÖ FAISS in RAM: Laden beim Startup
   ‚Üí Queries <1s statt 15s

‚úÖ Default Tab: Trialog
   ‚Üí App.tsx Line 166: activeTab = Tab.Trialog
```

### **TECH-STACK:**

**Frontend:**
- React 18 + Vite
- 12 Tabs (von V2.0 migriert)
- Port: 5173 (Dev-Server)

**Backend:**
- Python FastAPI (Port 8000)
- Komponenten:
  - `metrics_processor.py` (153 Metriken berechnen)
  - `trinity_engine.py` (12-DB Upload mit Chain-Hash)
  - `fastapi_gateway.py` (Unified API)
  - `llm_router.py` (Gemini + OpenAI Fallback)
  - `faiss_query.py` (in-memory FAISS)

**Daten:**
- FAISS: 384D, sentence-transformers (all-MiniLM-L6-v2)
  - Trialog/Antigravity: 7.413 Chunks (Code-Chats)
  - Evoki Temple: 33.795 Chunks (Therapeutische Gespr√§che + 153 Metriken)
- Deep Earth: 12 SQLite Layers (W_m1 bis W_p25)
- Regelwerk V12: 881 Regeln (JSON, CRC32: 3246342384)

---

## üé® DIE 12 TABS ERKL√ÑRT

| # | Tab | Zweck | Wichtigkeit |
|---|-----|-------|-------------|
| 1 | **Engine-Konsole** | Trinity Engine Status (Metriken-Engine Health) | üü° Monitoring |
| 2 | **Trialog ‚≠ê** | Multi-Agent Chat (Analyst, Regel, Synapse) | üî¥ **DEFAULT!** |
| 3 | **Agenten & Teams** | Agent-Auswahl & Konfiguration | üü¢ Optional |
| 4 | **Evoki's Tempel** | FAISS + Gemini + Live-Metriken (HERZST√úCK!) | üî¥ KRITISCH |
| 5 | **Metrik-Tuning** | 153 Metriken live anpassen (Schwellwerte, Gewichte) | üü° Tuning |
| 6 | **Analyse** | Metriken-Charts (√Ö, A, B-Vektor, Trauma-Timeline) | üü¢ Visualisierung |
| 7 | **Regelwerk-Suche** | Regelwerk V12 Browser (881 Regeln durchsuchen) | üü¢ Referenz |
| 8 | **API** | API-Keys, Temperaturen, Max-Tokens konfigurieren | üü° Config |
| 9 | **Stimme & API** | TTS Settings (Voice, Speed, Pitch) | üü¢ Optional |
| 10 | **Deep Storage** | FAISS-Browser (33.795 Chunks durchsuchen) | üü° Debugging |
| 11 | **Fehlerprotokoll** | Error Logs (Genesis-Anchor Violations, API-Errors) | üü° Debugging |
| 12 | **Pipeline Log** | Live Pipeline-Logs (Metrics ‚Üí FAISS ‚Üí Gemini) | üü° Debugging |

**User startet App:**
```typescript
// App.tsx Line 166
activeTab = Tab.Trialog  // ‚úÖ Trialog √∂ffnet sich, NICHT Temple!
```

---

## üíæ FAISS-SYSTEME IM VERGLEICH

### **TRIALOG/ANTIGRAVITY FAISS (f√ºr VS Code Agents):**

```yaml
Zweck: Programmier-Chats durchsuchbar machen
Location: tooling/data/faiss_indices/chatverlauf_final_20251020plus_dedup_sorted.faiss
Chunks: 7.413
Dimensions: 384D
Model: all-MiniLM-L6-v2
Daten: Reine Text-Chunks (KEINE Metriken!)
Zeitraum: Oktober 2025+
Nutzung: Code-Beispiele finden, Architektur-Diskussionen
Abfrage: Rein semantisch (Embedding ‚Üí FAISS ‚Üí Top-K)
```

**Beispiel-Query:**
```python
query = "Wie implementiere ich FastAPI mit SSE?"
‚Üí FAISS findet semantisch √§hnliche Code-Diskussionen
‚Üí Keine Metrik-Filterung
```

---

### **EVOKI TEMPEL FAISS (Therapeutisches Ged√§chtnis):**

```yaml
Zweck: Emotionale & kognitive Zust√§nde erinnern
Location: C:\Evoki V2.0\evoki-app\data\faiss_indices\ (‚Üí V3.0 migrieren)
Chunks: 33.795 (!!)
Dimensions: 384D (gleich wie Trialog)
Model: all-MiniLM-L6-v2 (gleich)
Daten: Text-Chunks + 1:1 Metrikdatenbank (153 Metriken pro Chunk!)
Zeitraum: Februar - Oktober 2025
Nutzung: Trauma-Erinnerungen, Heilungs-Fortschritt, Guardian Veto
Abfrage: HYBRID (60% Semantik + 40% Metrik-Match)
```

**DER ENTSCHEIDENDE UNTERSCHIED - HYBRID-RETRIEVAL:**

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                 EVOKI HYBRID-RETRIEVAL                  ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                         ‚îÇ
‚îÇ  1. FAISS Retrieval (Semantik):                        ‚îÇ
‚îÇ     User-Prompt embedden ‚Üí FAISS Search ‚Üí Top-10       ‚îÇ
‚îÇ                                                         ‚îÇ
‚îÇ  2. Metrikdatenbank 1:1 Mapping:                       ‚îÇ
‚îÇ     SQL: SELECT * FROM metriken WHERE chunk_id IN (top10)‚îÇ
‚îÇ     ‚Üí F√ºr SELBEN Chunks: 153 Metriken laden!           ‚îÇ
‚îÇ                                                         ‚îÇ
‚îÇ  3. Metriken f√ºr User-Prompt berechnen:                ‚îÇ
‚îÇ     T_panic, T_disso, A, PCI, X_exist, S_self, etc.    ‚îÇ
‚îÇ                                                         ‚îÇ
‚îÇ  4. Metrik-Matching:                                   ‚îÇ
‚îÇ     F√ºr jeden Chunk: Vergleiche Chunk-Metriken mit     ‚îÇ
‚îÇ     User-Prompt-Metriken ‚Üí metric_match_score          ‚îÇ
‚îÇ                                                         ‚îÇ
‚îÇ  5. Hybrid-Scoring:                                    ‚îÇ
‚îÇ     combined_score = 0.6*semantic + 0.4*metric_match   ‚îÇ
‚îÇ                                                         ‚îÇ
‚îÇ  6. Top-3 ausw√§hlen:                                   ‚îÇ
‚îÇ     Sortiere nach combined_score ‚Üí Beste 3 Chunks      ‚îÇ
‚îÇ                                                         ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**Beispiel-Abfrage:**

```python
User: "Ich f√ºhle mich so allein und wertlos"

# 1. FAISS findet (semantisch):
Chunk #482:  "isolation, einsamkeit, verlassen"     (semantic: 0.85)
Chunk #1293: "selbstwert, wertlos, versagen"        (semantic: 0.82)
Chunk #5721: "alltag, routine, normal"              (semantic: 0.41)

# 2. User-Prompt Metriken:
T_panic: 0.15
A (Affekt): 0.35
X_exist (Existenzielle Themen): 0.78  ‚Üê HOCH!
S_self (Selbstreferenz): 0.82          ‚Üê HOCH!

# 3. Chunk-Metriken (aus Datenbank):
Chunk #482:  X_exist=0.75, S_self=0.80  ‚Üí metric_match: 0.88
Chunk #1293: X_exist=0.82, S_self=0.85  ‚Üí metric_match: 0.92  ‚Üê BESTE!
Chunk #5721: X_exist=0.02, S_self=0.10  ‚Üí metric_match: 0.15

# 4. Combined Scores:
Chunk #1293: 0.82*0.6 + 0.92*0.4 = 0.860  ‚Üê WINNER!
Chunk #482:  0.85*0.6 + 0.88*0.4 = 0.862  ‚Üê SEHR NAH!
Chunk #5721: 0.41*0.6 + 0.15*0.4 = 0.306  ‚Üê RAUS!

# 5. Ergebnis: Top-3 = #1293, #482, n√§chstbester
```

**WARUM DAS WICHTIG IST:**

Rein semantisch w√ºrde Chunk #5721 ("alltag, routine") vielleicht auch gefunden, aber mit niedrigem Score. 

Mit Metrik-Matching wird er komplett rausgefiltert, weil **die emotionalen Zust√§nde** (X_exist, S_self) nicht passen!

‚Üí **Evoki erinnert nicht nur "√§hnliche W√∂rter", sondern "√§hnliche GEF√úHLE und GEDANKEN"!**

---

## üîÑ EVOKI TEMPEL PIPELINE (SCHRITT-F√úR-SCHRITT)

### **VOLLST√ÑNDIGER ABLAUF:**

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ              EVOKI TEMPEL V3.0 PIPELINE (SSE)                   ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                                 ‚îÇ
‚îÇ  USER                                                           ‚îÇ
‚îÇ    ‚îÇ                                                            ‚îÇ
‚îÇ    ‚ñº                                                            ‚îÇ
‚îÇ  [1] Prompt eingeben: "Ich f√ºhle mich so allein und wertlos"   ‚îÇ
‚îÇ    ‚îÇ                                                            ‚îÇ
‚îÇ    ‚ñº                                                            ‚îÇ
‚îÇ  FRONTEND (React Tab: Evoki's Tempel)                          ‚îÇ
‚îÇ    ‚îÇ                                                            ‚îÇ
‚îÇ    ‚îú‚îÄ‚Üí SSE Stream √∂ffnen: /api/temple/process-stream           ‚îÇ
‚îÇ    ‚îÇ                                                            ‚îÇ
‚îÇ    ‚ñº                                                            ‚îÇ
‚îÇ  BACKEND (FastAPI Port 8000)                                   ‚îÇ
‚îÇ    ‚îÇ                                                            ‚îÇ
‚îÇ    ‚îú‚îÄ‚Üí [2] Progress Event: "Metriken berechnen..."             ‚îÇ
‚îÇ    ‚îÇ         ‚îÇ                                                  ‚îÇ
‚îÇ    ‚îÇ         ‚ñº                                                  ‚îÇ
‚îÇ    ‚îÇ   metrics_processor.py:                                   ‚îÇ
‚îÇ    ‚îÇ   - calculate_full_spectrum(user_prompt)                  ‚îÇ
‚îÇ    ‚îÇ   - Lexika scannen (21 Terme-Sets)                        ‚îÇ
‚îÇ    ‚îÇ   - Core Metriken (A, PCI, coh, flow, z_prox)             ‚îÇ
‚îÇ    ‚îÇ   - Trauma (T_panic, T_disso, T_integ)                    ‚îÇ
‚îÇ    ‚îÇ   - FEP (phi_score, surprisal, EV_readiness)              ‚îÇ
‚îÇ    ‚îÇ   - GESAMT: 153 Metriken ‚Üí ~5s                            ‚îÇ
‚îÇ    ‚îÇ                                                            ‚îÇ
‚îÇ    ‚îú‚îÄ‚Üí [3] Progress Event: "FAISS durchsuchen..."              ‚îÇ
‚îÇ    ‚îÇ         ‚îÇ                                                  ‚îÇ
‚îÇ    ‚îÇ         ‚ñº                                                  ‚îÇ
‚îÇ    ‚îÇ   faiss_query.py (in-memory!):                            ‚îÇ
‚îÇ    ‚îÇ   - User-Prompt embedden (all-MiniLM-L6-v2)               ‚îÇ
‚îÇ    ‚îÇ   - FAISS Search (33.795 Chunks) ‚Üí Top-10                 ‚îÇ
‚îÇ    ‚îÇ   - Dauert <1s (Index schon in RAM!)                      ‚îÇ
‚îÇ    ‚îÇ                                                            ‚îÇ
‚îÇ    ‚îú‚îÄ‚Üí [4] Progress Event: "Metrik-Matching..."                ‚îÇ
‚îÇ    ‚îÇ         ‚îÇ                                                  ‚îÇ
‚îÇ    ‚îÇ         ‚ñº                                                  ‚îÇ
‚îÇ    ‚îÇ   SQL Query:                                              ‚îÇ
‚îÇ    ‚îÇ   - SELECT metriken WHERE chunk_id IN (top10)             ‚îÇ
‚îÇ    ‚îÇ   - F√ºr jeden Chunk: 153 Metriken aus DB laden            ‚îÇ
‚îÇ    ‚îÇ                                                            ‚îÇ
‚îÇ    ‚îÇ   Hybrid-Scoring:                                         ‚îÇ
‚îÇ    ‚îÇ   - metric_match = cosine(user_metrics, chunk_metrics)    ‚îÇ
‚îÇ    ‚îÇ   - combined = 0.6*semantic + 0.4*metric_match            ‚îÇ
‚îÇ    ‚îÇ   - Top-3 ausw√§hlen                                       ‚îÇ
‚îÇ    ‚îÇ                                                            ‚îÇ
‚îÇ    ‚îú‚îÄ‚Üí [5] Progress Event: "Kontext laden..."                  ‚îÇ
‚îÇ    ‚îÇ         ‚îÇ                                                  ‚îÇ
‚îÇ    ‚îÇ         ‚ñº                                                  ‚îÇ
‚îÇ    ‚îÇ   Chunk-Expansion:                                        ‚îÇ
‚îÇ    ‚îÇ   - F√ºr Top-3: Hole ¬±2 Nachbar-Chunks (falls zerteilt)    ‚îÇ
‚îÇ    ‚îÇ   - Lade letzte 4 Nachrichten (2 User + 2 Agent)          ‚îÇ
‚îÇ    ‚îÇ                                                            ‚îÇ
‚îÇ    ‚îú‚îÄ‚Üí [6] Progress Event: "Regelwerk einbinden..."            ‚îÇ
‚îÇ    ‚îÇ         ‚îÇ                                                  ‚îÇ
‚îÇ    ‚îÇ         ‚ñº                                                  ‚îÇ
‚îÇ    ‚îÇ   Regelwerk V12 laden:                                    ‚îÇ
‚îÇ    ‚îÇ   - CRC32 Check (3246342384) ‚Üí Bei Mismatch: HARD-STOP!   ‚îÇ
‚îÇ    ‚îÇ   - Relevante Regeln ausw√§hlen (A0, A29, A39, A46, A51)   ‚îÇ
‚îÇ    ‚îÇ                                                            ‚îÇ
‚îÇ    ‚îú‚îÄ‚Üí [7] Progress Event: "Gemini-Prompt bauen..."            ‚îÇ
‚îÇ    ‚îÇ         ‚îÇ                                                  ‚îÇ
‚îÇ    ‚îÇ         ‚ñº                                                  ‚îÇ
‚îÇ    ‚îÇ   llm_router.py:                                          ‚îÇ
‚îÇ    ‚îÇ   Prompt-Struktur:                                        ‚îÇ
‚îÇ    ‚îÇ   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îÇ
‚îÇ    ‚îÇ   ‚îÇ Du bist EVOKI, ein empathischer KI-Begleiter...‚îÇ     ‚îÇ
‚îÇ    ‚îÇ   ‚îÇ [Regelwerk V12 Auszug]                          ‚îÇ     ‚îÇ
‚îÇ    ‚îÇ   ‚îÇ                                                 ‚îÇ     ‚îÇ
‚îÇ    ‚îÇ   ‚îÇ WISSENSDATENBANK (Top 3):                       ‚îÇ     ‚îÇ
‚îÇ    ‚îÇ   ‚îÇ [Chunk #1293 vollst√§ndig]                       ‚îÇ     ‚îÇ
‚îÇ    ‚îÇ   ‚îÇ [Chunk #482 vollst√§ndig]                        ‚îÇ     ‚îÇ
‚îÇ    ‚îÇ   ‚îÇ [Chunk #... vollst√§ndig]                        ‚îÇ     ‚îÇ
‚îÇ    ‚îÇ   ‚îÇ                                                 ‚îÇ     ‚îÇ
‚îÇ    ‚îÇ   ‚îÇ VORHERIGE KONVERSATION:                         ‚îÇ     ‚îÇ
‚îÇ    ‚îÇ   ‚îÇ [Letzte 4 Nachrichten]                          ‚îÇ     ‚îÇ
‚îÇ    ‚îÇ   ‚îÇ                                                 ‚îÇ     ‚îÇ
‚îÇ    ‚îÇ   ‚îÇ AKTUELLE METRIKEN:                              ‚îÇ     ‚îÇ
‚îÇ    ‚îÇ   ‚îÇ A (Affekt): 0.35                                ‚îÇ     ‚îÇ
‚îÇ    ‚îÇ   ‚îÇ T_panic: 0.15                                   ‚îÇ     ‚îÇ
‚îÇ    ‚îÇ   ‚îÇ X_exist: 0.78                                   ‚îÇ     ‚îÇ
‚îÇ    ‚îÇ   ‚îÇ ...                                             ‚îÇ     ‚îÇ
‚îÇ    ‚îÇ   ‚îÇ                                                 ‚îÇ     ‚îÇ
‚îÇ    ‚îÇ   ‚îÇ USER-FRAGE:                                     ‚îÇ     ‚îÇ
‚îÇ    ‚îÇ   ‚îÇ "Ich f√ºhle mich so allein und wertlos"         ‚îÇ     ‚îÇ
‚îÇ    ‚îÇ   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îÇ
‚îÇ    ‚îÇ                                                            ‚îÇ
‚îÇ    ‚îú‚îÄ‚Üí [8] Progress Event: "Gemini antwortet..."               ‚îÇ
‚îÇ    ‚îÇ         ‚îÇ                                                  ‚îÇ
‚îÇ    ‚îÇ         ‚ñº                                                  ‚îÇ
‚îÇ    ‚îÇ   Gemini API Call:                                        ‚îÇ
‚îÇ    ‚îÇ   - Timeout: 90s (aber Frontend wartet via SSE!)          ‚îÇ
‚îÇ    ‚îÇ   - Bei 429/RESOURCE_EXHAUSTED: N√§chster API-Key          ‚îÇ
‚îÇ    ‚îÇ   - Bei Ersch√∂pfung aller Keys: OpenAI Fallback (30s)     ‚îÇ
‚îÇ    ‚îÇ                                                            ‚îÇ
‚îÇ    ‚îÇ   (Optional) A65 Candidate Scoring:                       ‚îÇ
‚îÇ    ‚îÇ   - 3 Response-Varianten generieren                       ‚îÇ
‚îÇ    ‚îÇ   - F√ºr jede: a65_score berechnen (17 Metriken)           ‚îÇ
‚îÇ    ‚îÇ   - Best: 0.6*a65 + 0.3*coherence + 0.1*diversity         ‚îÇ
‚îÇ    ‚îÇ                                                            ‚îÇ
‚îÇ    ‚îú‚îÄ‚Üí [9] Progress Event: "In 12 DBs speichern..."            ‚îÇ
‚îÇ    ‚îÇ         ‚îÇ                                                  ‚îÇ
‚îÇ    ‚îÇ         ‚ñº                                                  ‚îÇ
‚îÇ    ‚îÇ   trinity_engine.py:                                      ‚îÇ
‚îÇ    ‚îÇ   - Entry erstellen: {prompt, response, metrics, timestamp}‚îÇ
‚îÇ    ‚îÇ   - Chain-Hash berechnen: SHA256(session|round|...)       ‚îÇ
‚îÇ    ‚îÇ   - In 12 Deep Earth Layers schreiben:                    ‚îÇ
‚îÇ    ‚îÇ     tempel_W_m1, tempel_W_m2, tempel_W_m5, tempel_W_p25   ‚îÇ
‚îÇ    ‚îÇ     trialog_W_m1, trialog_W_m2, trialog_W_m5, trialog_W_p25‚îÇ
‚îÇ    ‚îÇ     (+ 4 more)                                             ‚îÇ
‚îÇ    ‚îÇ                                                            ‚îÇ
‚îÇ    ‚îú‚îÄ‚Üí [10] Complete Event: Finale Response!                   ‚îÇ
‚îÇ    ‚îÇ         ‚îÇ                                                  ‚îÇ
‚îÇ    ‚îÇ         ‚ñº                                                  ‚îÇ
‚îÇ    ‚îÇ   SSE Stream schlie√üen                                    ‚îÇ
‚îÇ    ‚îÇ                                                            ‚îÇ
‚îÇ    ‚ñº                                                            ‚îÇ
‚îÇ  FRONTEND                                                       ‚îÇ
‚îÇ    ‚îÇ                                                            ‚îÇ
‚îÇ    ‚îú‚îÄ‚Üí Response anzeigen                                       ‚îÇ
‚îÇ    ‚îú‚îÄ‚Üí Metriken-Charts updaten (A, PCI, Trauma-Timeline)       ‚îÇ
‚îÇ    ‚îî‚îÄ‚Üí Guardian Trip Icon (falls guardian_trip = 1)            ‚îÇ
‚îÇ                                                                 ‚îÇ
‚îÇ  USER sieht Response + Live-Metriken                            ‚îÇ
‚îÇ                                                                 ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**ZEITVERGLEICH V2.0 vs V3.0:**

```
V2.0:
- Metriken: 10s
- FAISS: 15s (CLI-Spawn!)
- Gemini: 90s
- GESAMT: 115s ‚Üí Timeout nach 60s!

V3.0:
- Metriken: 5s (Python schneller)
- FAISS: <1s (in RAM!)
- Gemini: 90s (aber kein Timeout via SSE!)
- GESAMT: ~96s, ABER Frontend wartet geduldig
```

---

## ‚öôÔ∏è KRITISCHE KOMPONENTEN

### **1. REGELWERK V12 (Genesis-Anchor)**

```yaml
File: app/interface/public/EVOKI_REGELWERKE_GENESIS/regelwerk_v12.json
Regeln: 881
CRC32: 3246342384
SHA256: ada4ecae8916fa7e5edd966a97b85af321b64ecfe12489fcea8c6dcef1bd4b1c

Kritische Regeln:
- A0: Direktive der Wahrheit (keine Konfabulation!)
- A29: W√§chter-Veto-Direktive (Guardian Trip)
- A37/A38: Erzwungene Regelwerks-Berechnung
- A51: Genesis-Anker-Protokoll (CRC32 ‚Üí HARD-STOP)

Enforcement:
- Bei JEDEM Start: CRC32 Check
- Bei Mismatch: System-Shutdown (A51)
```

**Check-Script:**
```python
import json, zlib

with open("app/interface/public/EVOKI_REGELWERKE_GENESIS/regelwerk_v12.json") as f:
    regelwerk = json.load(f)

regelwerk_str = json.dumps(regelwerk["rules"], sort_keys=True)
crc32 = zlib.crc32(regelwerk_str.encode()) & 0xFFFFFFFF

expected = 3246342384
assert crc32 == expected, f"INTEGRITY BREACH! {crc32} != {expected}"
```

---

### **2. METRIKEN-ENGINE (153 Metriken)**

```yaml
File: tooling/scripts/backend/metrics_processor.py
Lines: 815
Metriken: 153 (10 Kategorien)
Wichtigste Formeln:

# Trauma-Load
trauma_load = 0.4*T_panic + 0.3*T_disso + 0.2*(1-T_integ) + 0.1*dissociation

# Guardian Trip
guardian_trip = (is_critical OR z_prox > 0.65 OR t_panic > 0.8 OR hazard_score > 0.75)

# Affekt
A = 0.5 + (Emotion_pos - Emotion_neg) - T_panic

# B-Vektor (7D Empathie)
B_vec = [B_life, B_safety, B_truth, B_depth, B_warmth, B_clarity, B_score]
B_life >= 0.9 (KRITISCH!)
B_safety >= 0.8 (KRITISCH!)
```

**Test-Script:**
```python
from metrics_processor import calculate_full_spectrum

fs = calculate_full_spectrum(
    text="ich kann nicht mehr atmen, panik!",
    prev_text="",
    msg_id="test_001",
    speaker="user"
)

assert fs.T_panic > 0.8, f"T_panic zu niedrig: {fs.T_panic}"
assert fs.guardian_trip == 1, "Guardian Trip nicht ausgel√∂st!"
print("‚úÖ Metriken-Engine OK!")
```

---

### **3. TRINITY ENGINE (12-DB Upload)**

```yaml
File: tooling/scripts/backend/trinity_engine.py
DBs: 12 (tempel_W_m1/m2/m5/p25, trialog_W_m1/m2/m5/p25, + 4 more)
Format: JSONL (eine Zeile = ein Entry)
Chain-Hash: SHA256(session|round|prompt|response|timestamp)

Entry-Struktur:
{
  session_id, round_id, timestamp,
  user_prompt, agent_response,
  metrics: {17 Haupt-Metriken},
  full_metrics: {153 Metriken},
  chain_hash, prev_chain_hash
}
```

---

### **4. FAISS IN-MEMORY (Query <1s)**

```yaml
File: tooling/scripts/backend/faiss_query.py
Index: tooling/data/faiss_indices/evoki_temple_33795_chunks.faiss
Chunks: 33.795
Dimensions: 384D
Model: all-MiniLM-L6-v2

WICHTIG:
- Beim FastAPI-Startup laden! (@app.on_event("startup"))
- Nicht bei jeder Query neu laden!
- In RAM halten (global Variable)

Startup-Code:
@app.on_event("startup")
async def load_faiss():
    global faiss_index, chunks_metadata
    faiss_index = faiss.read_index("tooling/data/faiss_indices/...")
    with open("tooling/data/faiss_indices/...metadata.json") as f:
        chunks_metadata = json.load(f)
```

---

## üöÄ SETUP & START

### **INITIAL SETUP (EINMALIG):**

```bash
# 1. V2.0 Code extrahieren (PowerShell-Script ausf√ºhren)
# Siehe: ULTIMATE_MASTER_PLAN_V8.md ‚Üí PowerShell Master-Extraction-Script

# 2. Backend Dependencies
cd tooling\scripts\backend
pip install fastapi uvicorn python-multipart
pip install google-generativeai openai
pip install faiss-cpu numpy pandas sentence-transformers

# 3. Frontend Dependencies
cd app\interface
npm install

# 4. Genesis-Anchor Check
python -c "exec(open('check_genesis.py').read())"
# Muss ausgeben: ‚úÖ Genesis-Anchor OK!
```

---

### **T√ÑGLICHER START:**

```bash
# Terminal 1: Backend starten
cd tooling\scripts\backend
python fastapi_gateway.py
# ‚Üí Port 8000 aktiv, FAISS in RAM geladen

# Terminal 2: Frontend starten
cd app\interface
npm run dev
# ‚Üí Port 5173 aktiv

# Browser: http://localhost:5173
# ‚Üí Trialog Tab √∂ffnet sich (Default!)
```

---

### **HEALTH CHECKS:**

```bash
# Backend
curl http://localhost:8000/health
# ‚Üí {"status": "ok", "service": "EVOKI V3.0 Unified Backend"}

# FAISS
curl http://localhost:8000/api/faiss/health
# ‚Üí {"index_loaded": true, "chunks": 33795, "dimensions": 384}

# Metriken
curl -X POST http://localhost:8000/api/metrics/calculate \
  -H "Content-Type: application/json" \
  -d '{"text": "Test"}'
# ‚Üí {"success": true, "metrics": {...}}
```

---

## üõ†Ô∏è WARTUNG & DEBUGGING

### **LOGS:**

```bash
# Backend Logs
tail -f tooling/logs/fastapi_backend.log

# Frontend Console
# Browser ‚Üí DevTools ‚Üí Console

# Pipeline Logs
# UI ‚Üí Tab #12 "Pipeline √úberwachung"

# Error Logs
# UI ‚Üí Tab #11 "Fehlerprotokoll"
```

---

### **H√ÑUFIGE PROBLEME:**

**Problem:** Frontend zeigt "Backend nicht erreichbar"
```bash
# Check:
curl http://localhost:8000/health

# Fix:
cd tooling\scripts\backend
python fastapi_gateway.py
```

**Problem:** FAISS Queries dauern >10s
```bash
# Ursache: FAISS nicht in RAM!

# Check:
curl http://localhost:8000/api/faiss/health
# ‚Üí {"index_loaded": false}

# Fix: Backend neu starten
# Beim Startup MUSS load_faiss() aufgerufen werden!
```

**Problem:** Genesis-Anchor Violation
```bash
# Log zeigt: "INTEGRITY BREACH! CRC32 mismatch"

# Ursache: regelwerk_v12.json wurde ge√§ndert!

# Fix:
# 1. Backup wiederherstellen (Original von V2.0)
# 2. CRC32 Check:
python check_genesis.py
```

**Problem:** Timeout-Errors trotz SSE
```bash
# Ursache: Frontend nutzt noch fetch() statt EventSource

# Check App.tsx:
grep "fetch.*temple" app/interface/src/components/v2_tabs/EvokiTempleChat.tsx

# Fix: Ersetze fetch() mit EventSource (siehe ULTIMATE_MASTER_PLAN_V8.md)
```

---

## üìã CHECKLISTE: EVOKI KORREKT IMPLEMENTIERT?

```
‚úÖ Regelwerk V12 (881 Regeln) kopiert & CRC32 validiert
‚úÖ 12 Tabs implementiert & Default = Trialog
‚úÖ Backend Unified (nur Port 8000, kein Split!)
‚úÖ FAISS in RAM (laden beim Startup)
‚úÖ SSE f√ºr Temple Tab (kein Timeout!)
‚úÖ metrics_processor.py (153 Metriken berechnen)
‚úÖ trinity_engine.py (12-DB Upload)
‚úÖ Hybrid-Retrieval (60% Semantik + 40% Metrik)
‚úÖ Guardian Trip funktioniert (T_panic > 0.8 ‚Üí trip = 1)
‚úÖ Genesis-Anchor Enforcement (CRC32 bei jedem Start)
‚úÖ chronik.log (jede Interaktion gespeichert)
```

---

## üîí SCHREIBSCHUTZ

**Dieses Dokument ist SCHREIBGESCH√úTZT.**

√Ñnderungen erfordern:
1. Schreibschutz entfernen: `attrib -R HOW_TO_EVOKI_V3.md`
2. √Ñnderungen vornehmen
3. Schreibschutz wiederherstellen: `attrib +R HOW_TO_EVOKI_V3.md`

**Bei √Ñnderungen an der Architektur:**
- Dokumentiere in `ARCHITECTURE.txt`
- Update dieses Dokument
- Commit mit Begr√ºndung

---

**VERSION HISTORY:**

- V3.0 (2026-01-19): Initiale Version basierend auf vollst√§ndiger Discovery
- V3.1 (TBD): [Zuk√ºnftige √Ñnderungen hier dokumentieren]

---

**ENDE DES DOKUMENTS**
