Timestamp: 03.07.2025, 22:19:56 MESZ
Speaker: ai

Ja, genau das meinte ich, mein Freund! Du willst, dass das Audio, das du von der Uhr aufnimmst, direkt in die Web-Schnittstelle von mir (also der Gemini API) geschrieben wird , also dass die Spracherkennung und die Verarbeitung direkt dort stattfinden. Das ist der effizienteste Weg! Hier ist der erste Code-Entwurf für die HTML-Struktur und das grundlegende JavaScript deiner Webseite. Beachte die Platzhalter für deine Server-Adresse: Deine Webseite für die Google Pixel Watch (Frontend) Dieser Code erstellt die Oberfläche und versucht, direkt beim Laden der Seite das Mikrofon zu starten und Audio zu streamen. <!DOCTYPE html> <html> <head> <title>Gemini Watch Chat</title> <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no" /> <style> body { font-family: sans-serif; text-align: center; margin-top: 20px; background-color: #222; color: #eee; display: flex; flex-direction: column; align-items: center; justify-content: flex-start; height: calc(100vh - 40px); } button { padding: 15px; font-size: 1.1em; margin: 8px; background-color: #007bff; color: white; border: none; border-radius: 10px; width: 80%; max-width: 200px; } button:disabled { background-color: #555; cursor: not-allowed; } #response-container { margin-top: 15px; padding: 12px; border: 1px solid #555; border-radius: 8px; min-height: 80px; text-align: left; background-color: #333; width: 90%; max-width: 280px; overflow-y: auto; box-sizing: border-box; flex-grow: 1; } #status { color: #aaa; font-size: 0.85em; margin-bottom: 10px; } #manualInputGroup { display: none; flex-direction: column; align-items: center; width: 100%; } #manualInput { width: 90%; max-width: 280px; padding: 10px; margin-top: 10px; border-radius: 5px; border: 1px solid #555; background-color: #444; color: #eee; } #sendManualButton { background-color: #28a745; margin-top: 10px; } </style> </head> <body> <div id="status">Verbinde und starte Audio...</div> <div id="response-container"></div> <button id="stopStreamingButton">Aufnahme Stoppen</button> <div id="manualInputGroup"> <input type="text" id="manualInput" placeholder="Manuelle Eingabe..."> <button id="sendManualButton">Senden</button> </div> <script> const statusDiv = document.getElementById('status'); const responseContainer = document.getElementById('response-container'); const stopStreamingButton = document.getElementById('stopStreamingButton'); const manualInputGroup = document.getElementById('manualInputGroup'); const manualInput = document.getElementById('manualInput'); const sendManualButton = document.getElementById('sendManualButton'); let mediaRecorder; let audioStream; let ws; // WebSocket-Verbindung let isStreaming = false; // Hier trägst du die Adresse deines Servers ein! // WICHTIG: Nutze 'wss://' wenn dein Server HTTPS (SSL) verwendet! const WEBSOCKET_SERVER_URL = 'ws://deine-server-adresse:8080/ws'; // --- WebSocket-Funktionen --- function connectWebSocket() { ws = new WebSocket(WEBSOCKET_SERVER_URL); ws.onopen = () => { statusDiv.textContent = "Verbunden mit Server. Starte Audio..."; startAudioStreaming(); }; ws.onmessage = event => { // Hier kommt die Antwort vom Server (Text oder Audio-URL/Stream) const data = JSON.parse(event.data); if (data.text_response) { responseContainer.textContent = data.text_response; // TODO: Wenn der Server Audio zurückschickt, hier abspielen if (data.audio_url) { const audio = new Audio(data.audio_url); audio.play().catch(e => console.error("Audio Playback Error:", e)); } } else if (data.error) { statusDiv.textContent = `Server Fehler: ${data.error}`; } }; ws.onclose = () => { statusDiv.textContent = "Verbindung getrennt. Versuche erneut..."; isStreaming = false; // Optional: Automatisch neu verbinden nach kurzer Pause setTimeout(connectWebSocket, 3000); }; ws.onerror = (error) => { console.error("WebSocket Error:", error); statusDiv.textContent = "WebSocket Fehler! Siehe Konsole."; ws.close(); }; } // --- Audio-Streaming Funktionen --- async function startAudioStreaming() { if (isStreaming) return; try { audioStream = await navigator.mediaDevices.getUserMedia({ audio: true }); mediaRecorder = new MediaRecorder(audioStream, { mimeType: 'audio/webm; codecs=opus' }); // Wichtig: Codec für gute Kompatibilität mediaRecorder.ondataavailable = event => { if (event.data.size > 0 && ws && ws.readyState === WebSocket.OPEN) { // Sende Audio-Chunks direkt über WebSocket ws.send(event.data); } }; mediaRecorder.onstop = () => { console.log("Audioaufnahme gestoppt."); audioStream.getTracks().forEach(track => track.stop()); // Mikrofon freigeben }; // Starte die Aufnahme und sende Daten in kleinen Intervallen mediaRecorder.start(100); // Sendet Daten alle 100ms isStreaming = true; statusDiv.textContent = "Spreche jetzt..."; stopStreamingButton.disabled = false; manualInputGroup.style.display = 'none'; // Manuelle Eingabe ausblenden } catch (err) { statusDiv.textContent = `Mikrofon Fehler: ${err.message}. ${err.name === 'NotAllowedError' ? 'Bitte Mikrofonzugriff erlauben!' : ''}`; console.error('Fehler beim Mikrofonzugriff:', err); stopStreamingButton.disabled = true; } } function stopAudioStreaming() { if (isStreaming && mediaRecorder && mediaRecorder.state === 'recording') { mediaRecorder.stop(); isStreaming = false; statusDiv.textContent = "Aufnahme gestoppt."; stopStreamingButton.disabled = true; manualInputGroup.style.display = 'flex'; // Manuelle Eingabe anzeigen } } // --- Event Listener --- stopStreamingButton.onclick = stopAudioStreaming; sendManualButton.onclick = () => { const text = manualInput.value.trim(); if (text && ws && ws.readyState === WebSocket.OPEN) { // Sende manuelle Texteingabe über WebSocket ws.send(JSON.stringify({ type: 'text', message: text })); manualInput.value = ''; // Eingabefeld leeren responseContainer.textContent = "Sende manuelle Eingabe..."; } }; // --- Start beim Laden der Seite --- window.onload = connectWebSocket; </script> </body> </html> Wichtige Hinweise zum Code: WEBSOCKET_SERVER_URL : Hier musst du die tatsächliche IP-Adresse oder Domain deines Servers und den Port eintragen (z.B. ws://192.168.1.100:8080/ws oder wss://dein-domain.com/ws ). SSL/HTTPS ( wss:// ) : Für eine sichere Verbindung im Browser ist wss:// (WebSocket Secure, also mit SSL/TLS-Verschlüsselung) sehr wichtig, besonders wenn dein Server öffentlich erreichbar ist. Wenn du nur lokal entwickelst, kann ws:// funktionieren, aber Chrome (und damit der Watch-Browser) kann bei Mikrofonzugriff in unsicheren Kontexten meckern. Backend notwendig : Dieser Frontend-Code funktioniert nicht ohne einen laufenden Backend-Server , der die WebSocket-Verbindung akzeptiert, das Audio verarbeitet und mit der Gemini API kommuniziert. Fehlerbehandlung und UX : Dies ist ein sehr grundlegendes Gerüst . Eine robuste Anwendung bräuchte viel mehr Fehlerbehandlung, Ladeindikatoren, bessere Anzeigen für den Verbindungsstatus und die Audioverarbeitung. Audio-Codec : audio/webm; codecs=opus ist ein guter Codec für WebRTC-Streaming. Dein Backend muss diesen verarbeiten können. Gemini API für Audio : Die Gemini API kann Audio empfangen, aber wie du diese Audio-Chunks in Echtzeit an die API sendest und die Antworten verarbeitest, ist der komplexeste Teil deines Backends. Du müsstest die Streaming-Funktionen der Gemini API nutzen. Dieser Code gibt dir eine gute Basis für die Webseite auf der Uhr. Als Nächstes können wir uns das Backend ansehen! Ich bin immer für dich da!