Timestamp: 14.10.2025, 03:25:42 MESZ
Speaker: ai

Absolut, das ist ein entscheidender Sicherheitspunkt. Um zu verhindern, dass Endlosschleifen oder fehlerhafte Logik die API-Kosten durch wiederholte Aufrufe explodieren lassen (eine valide Sorge im Kontext von A52, falls eine Wiederholungslogik implementiert würde), bauen wir eine zweistufige Sicherheitsfunktion ein: einen internen API-Aufruf-Limiter und einen externen Anfrage-Timeout . 1. Innere Schutzschicht: Der API-Aufruf-Limiter (Code-Ebene) Wir modifizieren die ChrononEngine so, dass sie pro eingehender Nutzeranfrage nur eine streng limitierte Anzahl an Aufrufen an die teure Gemini-API durchführen kann. Dies ist der direkteste Schutz vor Kostenexplosion. Anpassungen in evoki_engine.py Wir führen einen Zähler ein, der bei jeder Interaktion zurückgesetzt wird. # Dateiname: evoki_engine.py # ... (andere Imports) ... class ChrononEngine: # FÜGE DIESE KONSTANTE HINZU MAX_API_CALLS_PER_INTERACTION = 4 # Erlaubt die 2 Standard-Aufrufe (Math/Semantic) + eine potentielle Korrekturschleife def __init__(self, storage_path="/var/data"): # ... (bisherige Initialisierung) ... self.api_call_counter = 0 # Initialisiere den Zähler # FÜGE DIESE NEUE, SICHERE WRAPPER-METHODE HINZU def _safe_cognitive_generate(self, *args, **kwargs): """ Ein sicherer Wrapper, der die API-Aufrufe zählt und limitiert. Verhindert Endlosschleifen und Kostenexplosion gemäß A52-Sicherheitsprinzip. """ if self.api_call_counter >= self.MAX_API_CALLS_PER_INTERACTION: raise SystemCriticalError( "Sicherheitsprotokoll: Maximale API-Aufrufe pro Interaktion überschritten. Breche ab, um Endlosschleife zu verhindern." ) self.api_call_counter += 1 # Hier wird der eigentliche Aufruf zum Cognitive Core (z.B. Gemini) durchgeführt # Annahme: self.cognitive_core.generate ist die Methode, die die API aufruft return self.cognitive_core.generate(*args, **kwargs) def process_interaction(self, user_input: str) -> dict: # SETZE DEN ZÄHLER BEI JEDER NEUEN ANFRAGE ZURÜCK self.api_call_counter = 0 # ... (restliche Logik der Methode) ... # Beispielhafte Anwendung im Standard-Flow: # Ersetze die direkten Aufrufe an self.cognitive_core.generate # mit unserem neuen sicheren Wrapper. # ALT: # result_math = self.cognitive_core.generate(user_input, "MATH", context_memories) # result_semantics = self.cognitive_core.generate(user_input, "SEMANTIC", context_memories) # NEU: # result_math = self._safe_cognitive_generate(user_input, "MATH", context_memories) # result_semantics = self._safe_cognitive_generate(user_input, "SEMANTIC", context_memories) # ... (restlicher Code) ... 2. Äußere Schutzschicht: Der Anfrage-Timeout (Infrastruktur-Ebene) Zusätzlich sorgt der Webserver (Gunicorn, der von Render und Google Cloud Run standardmäßig genutzt wird) dafür, dass keine einzelne Anfrage unendlich lange laufen kann. Wenn dein Code aus irgendeinem Grund hängt, wird der Prozess nach einer festgelegten Zeit automatisch beendet. Anpassungen in der render.yaml oder Start-Befehl Du kannst Gunicorn anweisen, einen Timeout zu verwenden. Eine typische Zeit sind 60 Sekunden. Beispiel für den startCommand : # In deiner render.yaml oder als Start-Befehl für Google Cloud Run # ALT: startCommand: "gunicorn app:app" # NEU: startCommand: "gunicorn --timeout 60 app:app" Zusammenfassung der Sicherheitsmaßnahmen Mit dieser Kombination hast du eine doppelte Absicherung: Der Limiter verhindert gezielt, dass die Logik Amok läuft und viele API-Calls in kurzer Zeit absetzt. Er ist deine Kostenbremse . Der Timeout ist dein Not-Aus-Schalter , der das gesamte System schützt, falls ein Prozess (nicht nur die KI-API) unerwartet lange dauert. So ist sichergestellt, dass die Kosten kontrollierbar bleiben und das System auch bei unvorhergesehenen Fehlern stabil bleibt.