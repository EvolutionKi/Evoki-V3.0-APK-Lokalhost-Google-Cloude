Timestamp: 14.10.2025, 04:03:44 MESZ
Speaker: ai

No, the code I just provided does not contain the new logic for the API, file uploads, or the web server. That file, master_blaupause_core.py , is only the first module in our modular reconstruction. It represents the foundational "constitution" of the system—the unchangeable rulebook. We are now building the complete system piece by piece, just as you requested. I will give you each self-contained module one by one. The logic for the API, the web server ( app.py ), and the connection to the HTML window will come in the subsequent modules. Let's continue with the next logical piece. ## Modul 2: services.py This file contains the helper classes that provide essential services to the main engine. It includes the VectorizationService for creating text embeddings and, most importantly, the real CognitiveCore that connects to the live Google Gemini API. Anleitung: Erstelle eine neue Datei mit dem Namen services.py und füge den folgenden, vollständigen Code ein. # Dateiname: services.py # Zweck: Stellt grundlegende Dienste wie Vektorisierung und die Anbindung an das Sprachmodell (LLM) bereit. import numpy as np import hashlib import google.generativeai as genai # ============================================================================== # 1. VEKTORISIERUNGS-DIENST # ============================================================================== class VectorizationService: """ Simuliert Text-Embeddings deterministisch durch Hashing. Dies stellt sicher, dass der gleiche Text immer den exakt gleichen Vektor erzeugt. """ def __init__(self, dimensions: int = 64): self.dimensions = dimensions def vectorize(self, text: str) -> np.ndarray: """Wandelt einen Text in einen normalisierten 64-dimensionalen Vektor um.""" if not text: return np.zeros(self.dimensions, dtype=np.float32) # Nutze SHA-512 für einen ausreichend großen und deterministischen Hash hash_bytes = hashlib.sha512(text.encode('utf-8')).digest() # Erzeuge den Vektor aus den Hash-Bytes vector = np.array([ # Normalisiere jeden Bytewert auf den Bereich [-1.0, 1.0] (hash_bytes[i % len(hash_bytes)] / 127.5) - 1.0 for i in range(self.dimensions) ], dtype=np.float32) return self._normalize(vector) def _normalize(self, vector: np.ndarray) -> np.ndarray: """Normalisiert einen Vektor auf die Einheitslänge (Länge 1), um Kosinus-Ähnlichkeit zu ermöglichen.""" norm = np.linalg.norm(vector) # Verhindert eine Division durch Null oder unendliche Werte if norm == 0 or not np.isfinite(norm): return np.zeros_like(vector) return vector / norm def cosine_similarity(self, v1: np.ndarray, v2: np.ndarray) -> float: """ Berechnet die Kosinus-Ähnlichkeit zwischen zwei Vektoren. Annahme: Die Vektoren sind bereits normalisiert. """ try: # Stelle sicher, dass die Vektoren keine ungültigen Zahlen (NaN, Inf) enthalten if not np.isfinite(v1).all() or not np.isfinite(v2).all(): return 0.0 # Für Einheitsvektoren ist die Ähnlichkeit einfach das Skalarprodukt return np.dot(v1, v2) except ValueError: return 0.0 # ============================================================================== # 2. KOGNITIVER KERN (LLM-ANBINDUNG) # ============================================================================== class CognitiveCore: """ Die Schnittstelle zur Google Gemini API. Dies ist die tatsächliche, funktionierende Implementierung, die den alten Platzhalter ersetzt. """ def __init__(self, model_name: str = 'gemini-1.5-flash-latest'): try: self.model = genai.GenerativeModel(model_name) print(f"INFO: CognitiveCore erfolgreich mit dem Modell '{model_name}' initialisiert.") except Exception as e: print(f"FATALER FEHLER bei der Initialisierung des Gemini-Modells: {e}") self.model = None def generate(self, prompt: str): """ Sendet eine Anfrage an die Gemini API und gibt das volle Antwortobjekt zurück, das sowohl den Text als auch die Nutzungs-Metadaten (Token-Anzahl) enthält. """ if not self.model: raise ConnectionError("CognitiveCore ist nicht initialisiert. API-Aufruf kann nicht durchgeführt werden.") try: response = self.model.generate_content( prompt, generation_config=genai.types.GenerationConfig(temperature=0.7) ) return response except Exception as e: print(f"FATALER API FEHLER im CognitiveCore während der Generierung: {e}") # Leite den Fehler weiter, damit die ChrononEngine ihn behandeln kann raise IOError(f"Fehler bei der Kommunikation mit der Gemini API: {e}")