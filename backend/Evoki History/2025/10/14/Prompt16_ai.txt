Timestamp: 14.10.2025, 03:32:18 MESZ
Speaker: ai

Absolut. Ich verstehe jetzt ganz genau, was du meinst. Mein Fehler, dass ich den vorherigen Code fehlinterpretiert habe. Wir machen das jetzt genau richtig: Wir nehmen die Essenz deiner 10 ursprünglichen Skripte und schmieden sie zu einem einzigen, robusten System, das aus drei finalen Dateien besteht: evoki_engine.py : Das Herzstück. Alle Klassen, Regeln und die gesamte Logik kommen hier rein. app.py : Das Gehirn. Der Webserver, der Anfragen annimmt, die Engine steuert und die Sicherheit gewährleistet. index.html : Das Gesicht. Die saubere Benutzeroberfläche für den Dialog. Ich werde dir den Code jetzt Stück für Stück geben, logisch geordnet und mit Kommentaren versehen, damit du ihn extern zusammensetzen kannst. Fangen wir mit der größten und wichtigsten Datei an: evoki_engine.py . Teil 1: evoki_engine.py - Das Herzstück Wir beginnen damit, die fundamentalen Definitionen, das Regelwerk und die grundlegenden Service-Klassen zu schaffen. Anleitung: Kopiere den folgenden Code-Block und speichere ihn als evoki_engine.py . Wir werden diese Datei in den nächsten Schritten erweitern. # Dateiname: evoki_engine.py # TEIL 1: GRUNDLAGEN, REGELWERK & SERVICES import os import json import hashlib import zlib import math import datetime import re import copy import threading from typing import Dict, List, Any, Optional, Tuple from datetime import timezone import numpy as np import google.generativeai as genai # ============================================================================== # 1. KERN-DEFINITIONEN & REGELWERK # Logik aus: master_blaupause_core.py # ============================================================================== class SystemCriticalError(Exception): """Benutzerdefinierte Exception für kritische Systemfehler, die einen HARD-STOP erzwingen.""" pass # HINWEIS: Füge hier den vollständigen Text von MASTER_BLAUPAUSE_CORE_TEXT aus deiner Datei ein. # Er ist zu lang, um ihn hier komplett darzustellen, aber entscheidend für die Funktion. MASTER_BLAUPAUSE_CORE_TEXT = """ Master-Blaupause V5.0 (Die Diamant-Synthese) Dokumentname: Genesis-Anker-Protokoll (Historisch Vollständig) ... (DEIN VOLLSTÄNDIGER REGELWERKSTEXT HIER EINFÜGEN) ... """ # A51: Berechnung der Genesis-Prüfsumme zur Laufzeit GENESIS_ANKER_SOLL_CRC32 = zlib.crc32(MASTER_BLAUPAUSE_CORE_TEXT.encode('utf-8')) class Regelwerk: """Verwaltet das vollständige Regelwerk und die davon abgeleiteten Anker.""" def __init__(self): self.regelwerk_komplett = MASTER_BLAUPAUSE_CORE_TEXT self.genesis_hash_crc32 = GENESIS_ANKER_SOLL_CRC32 self.manifestations_anker = datetime.datetime(1991, 1, 31, tzinfo=timezone.utc) # ============================================================================== # 2. SERVICES & INFRASTRUKTUR # Logik aus: services.py (angepasst für die echte API) # ============================================================================== class VectorizationService: """Simuliert Embeddings deterministisch durch Hashing für Konsistenz.""" def __init__(self, dimensions=64): self.dimensions = dimensions def vectorize(self, text: str) -> np.ndarray: if not text: return np.zeros(self.dimensions, dtype=np.float32) hash_bytes = hashlib.sha512(text.encode('utf-8')).digest() vector = np.array([ (hash_bytes[i % len(hash_bytes)] / 127.5) - 1.0 for i in range(self.dimensions) ], dtype=np.float32) return self._normalize(vector) def _normalize(self, vector: np.ndarray) -> np.ndarray: norm = np.linalg.norm(vector) if norm == 0 or not np.isfinite(norm): return np.zeros_like(vector) return vector / norm def cosine_similarity(self, v1: np.ndarray, v2: np.ndarray) -> float: try: if not np.isfinite(v1).all() or not np.isfinite(v2).all(): return 0.0 return np.dot(v1, v2) except ValueError: return 0.0 class CognitiveCore: """Schnittstelle zur Google Gemini API.""" def __init__(self, model_name='gemini-1.5-flash-latest'): self.model = genai.GenerativeModel(model_name) print(f"INFO: CognitiveCore mit Modell '{model_name}' initialisiert.") def generate(self, kontextualisierter_prompt: str, system_anweisung: str): """Sendet eine Anfrage an die Gemini API und gibt das volle Antwortobjekt zurück.""" try: # Erstelle die Konversationshistorie für den API-Aufruf # In einer echten Implementierung würde hier der gesamte Chatverlauf stehen contents = [{"role": "user", "parts": [{"text": kontextualisierter_prompt}]}] # Das System Instruction Feature von Gemini nutzen system_instruction = {"role": "system", "parts": [{"text": system_anweisung}]} response = self.model.generate_content( contents, generation_config=genai.types.GenerationConfig(temperature=0.7), # system_instruction wird für neuere Modelle direkt im generate_content erwartet # Für ältere Modelle müsste es Teil der contents-Liste sein. ) return response except Exception as e: print(f"FATALER API FEHLER im CognitiveCore: {e}") # Erzeuge ein "Dummy"-Antwortobjekt im Fehlerfall, um das System nicht abstürzen zu lassen from google.generativeai.types import GenerateContentResponse # Diese Mock-Erstellung ist komplex, stattdessen werfen wir einen Fehler raise IOError(f"Fehler bei der Kommunikation mit der Gemini API: {e}") # --- ENDE VON TEIL 1 --- # Im nächsten Schritt fügen wir den Speicher-Adapter und die Logik-Module hinzu. Sobald du diesen ersten Block hast, gib mir ein Zeichen, und ich gebe dir den nächsten Teil für die evoki_engine.py .