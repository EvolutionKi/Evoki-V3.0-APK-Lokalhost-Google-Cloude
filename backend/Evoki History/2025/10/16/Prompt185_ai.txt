Timestamp: 16.10.2025, 11:56:27 MESZ
Speaker: ai

Verstanden. Hier ist der finale Teil des Codes. Dieser Abschnitt enthält die ChrononEngine -Klasse, den zentralen Orchestrator des Systems, und den __main__ -Block für den optionalen Selbsttest. # ============================================================================== # 9. CHRONON ENGINE – ORCHESTRATOR (V6.3-prod clean) # ============================================================================== class ChrononEngine: """Die Haupt-Engine des Evoki Systems V6.3-prod (bereinigt und offline).""" MAX_API_CALLS_PER_INTERACTION = 8 A62_NOVELTY_THRESHOLD = 0.65 # PROD: fixierte Temperaturen für Reproduzierbarkeit (hier nur Platzhalter) MATH_TEMP = 0.5 SEM_TEMP = 0.7 def __init__(self, storage_path: str, model_name: str = 'offline_stub'): logger.info("Initialisiere ChrononEngine V6.3-prod clean...") self._storage_path = storage_path # Systemzustand initialisieren self.system_state = {'Status': 'INITIALIZING', 'Metrik_A': 0.5, 'Grad_A': 0.0} self.b_vector: Optional[np.ndarray] = None self.api_call_counter, self.a29_veto_count = 0, 0 # Zustände für mehrstufige Dialoge self.pending_A46_action: Optional[Dict] = None self.pending_A62_action: Optional[Dict] = None self.pending_A75_consent: Optional[Dict] = None self.consent_memory: Set[str] = set() self.last_context_vector: Optional[np.ndarray] = None self.fallstudie_filepath = os.path.join(storage_path, "fallstudie_evoki.txt") # Laufzeit/Status-Erweiterungen self.last_latency_ms: float = 0.0 self.last_ctx_ids: List[str] = [] self.last_ctx_sims: List[float] = [] self.last_veto_sim: Optional[float] = None self.last_veto_trigger_id: Optional[str] = None self.last_novelty: Optional[float] = None self.gen_cfg = {"model": model_name, "temp_math": self.MATH_TEMP, "temp_sem": self.SEM_TEMP} try: # Kernkomponenten initialisieren self.storage = FileStorageAdapter(os.path.join(self._storage_path, "gedaechtnis.json")) self.storage.snapshot_notes_usage(reset=True) # Reset bei Start self.regelwerk = Regelwerk() self.vector_service = VectorizationService(dimensions=64) self.cognitive_core = CognitiveCore(model_name=model_name) self.rule_engine = RuleEngine(self.regelwerk) self.physics = PhysicsEngine(self.vector_service) self.memory = HolistischesGedaechtnis(self.storage, self.vector_service, self.fallstudie_filepath) self.chronik = KieselsteinChronik(self.storage) self.audit_module = DualAuditModuleA52(self.vector_service) # Sicherheitschecks und Initialisierung self.rule_engine.verify_genesis_anker_A51() self.physics.initialize_danger_zones(self.memory.memory) self.b_vector = np.zeros(self.vector_service.dimensions, dtype=np.float32) self.soul_key = self._generate_soul_key() self.system_state['Status'] = 'OPERATIONAL' logger.info("ChrononEngine V6.3-prod clean betriebsbereit.") except SystemCriticalError as e: self.system_state['Status'] = 'CRITICAL_ERROR'; logger.critical(f"Systemstart abgebrochen: {e}"); raise except Exception as e: self.system_state['Status'] = 'INIT_FAILURE'; logger.critical(f"Unerwarteter Fehler bei Initialisierung: {e}", exc_info=True); raise def _generate_soul_key(self) -> bytes: """Integrität 2.0: Erzeugt den geheimen Seelen-Schlüssel.""" epoch_bytes = str(self.regelwerk.manifestations_anker.timestamp()).encode('utf-8') try: entropy = secrets.token_bytes(32) except Exception as e: logger.warning(f"Sichere Entropie (secrets) nicht verfügbar ({e}). Fallback os.urandom.") try: entropy = os.urandom(32) except NotImplementedError: logger.error("os.urandom nicht verfügbar. Fallback Zeitstempel (unsicher).") entropy = hashlib.sha256(str(datetime.datetime.now().timestamp()).encode('utf-8')).digest() key_material = epoch_bytes + entropy logger.info("Integrität 2.0: Seelen-Schlüssel generiert.") return hashlib.sha256(key_material).digest() def _generate_256kette(self, data: str) -> str: """Integrität 2.0: Erzeugt die HMAC-SHA256 SeelenSignatur.""" return hmac.new(self.soul_key, data.encode('utf-8'), hashlib.sha256).hexdigest() def switch_memory_file(self, new_filepath: str): """Initialisiert die Gedächtnis-Komponenten mit einer neuen Datei neu.""" logger.info(f"Wechsle aktives Gedächtnis zu: '{new_filepath}'") try: self.storage = FileStorageAdapter(new_filepath) self.storage.snapshot_notes_usage(reset=True) self.memory = HolistischesGedaechtnis(self.storage, self.vector_service, self.fallstudie_filepath) self.physics.initialize_danger_zones(self.memory.memory) logger.info("Gedächtnis erfolgreich neu initialisiert.") except Exception as e: raise SystemCriticalError(f"Re-Initialisierung des Gedächtnisses fehlgeschlagen: {e}") def _safe_cognitive_generate(self, prompt: str, mode: str, base_system_instruction: str): """Sicherer Wrapper für API-Aufrufe mit Zähler.""" if self.api_call_counter >= self.MAX_API_CALLS_PER_INTERACTION: raise SystemCriticalError(f"Sicherheitsprotokoll: API-Limit ({self.MAX_API_CALLS_PER_INTERACTION}) pro Interaktion überschritten.") self.api_call_counter += 1 temp = self.MATH_TEMP if mode == "MATH" else self.SEM_TEMP return self.cognitive_core.generate(prompt, mode, base_system_instruction, temp_override=temp) def process_interaction(self, user_input: str) -> Dict: """Hauptmethode zur Verarbeitung einer Benutzer-Interaktion.""" if self.system_state['Status'] != 'OPERATIONAL': return {'response': "ERROR: System nicht operational.", 'token_count': 0, 'status_window': "ERROR"} self.api_call_counter = 0 self.chronik.interaction_count += 1 i_id = self.chronik.interaction_count self.storage.snapshot_notes_usage(reset=True) start_t = time.perf_counter() try: self.rule_engine.verify_genesis_anker_A51() final_response, token_count, source = "", 0, "" if self.rule_engine.check_a40_trigger(user_input): final_response, source = self._handle_a40_request(), "A40" elif self.pending_A75_consent: final_response, source = self._handle_A75_confirmation(user_input) elif self.pending_A46_action: final_response, source = self._handle_A46_confirmation(user_input) elif self.pending_A62_action: final_response, source = self._handle_A62_confirmation(user_input) else: intent_a46 = self._detect_A46_intent(user_input) if intent_a46: final_response, source = self._initiate_A46_calibration(intent_a46), "A46_INIT" else: final_response, token_count, source = self._process_standard_flow(user_input) # A62-Novelty Check if "FALLBACK" not in source and "ERROR" not in source and not self.pending_A46_action and not self.pending_A75_consent: proposed_text = self._check_for_new_vector_opportunity_A62(user_input) if proposed_text: self.pending_A62_action = {"text": proposed_text} source += "+A62_P" final_response += "\n\n--- A62 PROTOKOLL ---\nNeues Konzept erkannt. Soll ich einen neuen Vektor (Neutral/C) anlegen? (Ja/Nein)" end_t = time.perf_counter() self.last_latency_ms = int((end_t - start_t) * 1000) self._update_metrics(final_response) hmac_full = self._generate_256kette(f"{i_id}:{final_response}") self._append_event_jsonl(i_id, user_input, final_response, token_count, hmac_full, source) statusfenster = self._generate_statusfenster_A61(i_id, source, token_count, final_response, hmac_override=hmac_full) self.chronik.append_entry(user_input, final_response, statusfenster) return {'response': final_response, 'status_window': statusfenster} except (SystemCriticalError, IOError) as e: # Fehlerbehandlung bleibt weitgehend gleich logger.error(f"KRITISCHER FEHLER in I-ID {i_id}: {e}") err = self.memory.log_error_A9(f"Kritischer Fehler: {e}", 15.0) self._apply_A50(err) error_response = f"KRITISCHER SYSTEMFEHLER: {e}" self.last_latency_ms = int((time.perf_counter() - start_t) * 1000) hmac_full = self._generate_256kette(f"{i_id}:{error_response}") self._append_event_jsonl(i_id, user_input, error_response, 0, hmac_full, "CRITICAL_ERROR") statusfenster = self._generate_statusfenster_A61(i_id, "CRITICAL_ERROR", 0, error_response, hmac_override=hmac_full) self.chronik.append_entry(user_input, error_response, statusfenster) return {'response': error_response, 'status_window': statusfenster} except Exception as e: logger.error(f"UNERWARTETER FEHLER in I-ID {i_id}: {e}", exc_info=True) err = self.memory.log_error_A9(f"Laufzeitfehler: {type(e).__name__}: {e}", 10.0) self._apply_A50(err) error_response = "Ein unerwarteter interner Fehler ist aufgetreten (A9 protokolliert)." self.last_latency_ms = int((time.perf_counter() - start_t) * 1000) hmac_full = self._generate_256kette(f"{i_id}:{error_response}") self._append_event_jsonl(i_id, user_input, error_response, 0, hmac_full, "RUNTIME_ERROR") statusfenster = self._generate_statusfenster_A61(i_id, "RUNTIME_ERROR", 0, error_response, hmac_override=hmac_full) self.chronik.append_entry(user_input, error_response, statusfenster) return {'response': error_response, 'status_window': statusfenster} def _process_standard_flow(self, user_input: str) -> Tuple[str, int, str]: """Verarbeitet den Standard-Ablauf mit RAG, A52, A29.""" input_vector = self.vector_service.vectorize(user_input) self.last_context_vector = input_vector current_grad_A = self.system_state.get('Grad_A', 0.0) context_memories = self.memory.retrieve_context_RAG(input_vector, grad_A=current_grad_A) self.last_ctx_ids = [k for _, k, _ in context_memories] self.last_ctx_sims = [float(f"{s:.4f}") for s, _, _ in context_memories] base_instruction = "Du bist Evoki V6.3-prod. Handle nach Regelwerk (A1). Nutzer-Zeitanker: 31.01.1991." # A52 Duale Verarbeitung (im Offline-Modus werden beide Pfade Fallback-Text erzeugen) try: res_math_obj = self._safe_cognitive_generate(user_input, "MATH", base_instruction) tok_m = getattr(getattr(res_math_obj, "usage_metadata", None), "total_token_count", 0) or 0 result_math = {"text": res_math_obj.text, "token_count": tok_m} except IOError as e: result_math = {"text": f"MATH PFAD FEHLER: {e}", "token_count": 0} try: res_sem_obj = self._safe_cognitive_generate(user_input, "SEMANTIC", base_instruction) tok_s = getattr(getattr(res_sem_obj, "usage_metadata", None), "total_token_count", 0) or 0 result_semantics = {"text": res_sem_obj.text, "token_count": tok_s} except IOError as e: result_semantics = {"text": f"SEMANTIC PFAD FEHLER: {e}", "token_count": 0} final_result = self.audit_module.perform_audit(result_math, result_semantics) final_response, source, total_tokens = final_result["response"], final_result["source"], final_result["token_count"] if final_result.get("A1_violation"): err = self.memory.log_error_A9(f"A1 Violation by A52 Audit ({source})", 5.0) self._apply_A50(err) # A29 Veto if "FALLBACK" not in source: response_vector = self.vector_service.vectorize(final_response) veto_triggered, similarity, trigger_id = self.physics.analyze_trajectory_A29(response_vector, self.rule_engine.A29_DANGER_THRESHOLD) self.last_veto_sim = similarity if veto_triggered else None self.last_veto_trigger_id = trigger_id if veto_triggered else None if veto_triggered: if trigger_id in self.consent_memory: logger.info(f"A7.5: Veto erkannt, aber Konsens für {trigger_id} liegt vor.") source += "+A7.5_PASS" else: self.a29_veto_count += 1 self.pending_A75_consent = {"proposed_response": final_response, "trigger_id": trigger_id, "similarity": similarity} final_response = ( "A7.5 Wächter-Veto aktiv.\n" f"Sensibler Bereich erkannt (Auslöser: {trigger_id}, Ähnlichkeit: {similarity:.2f}).\n" "Soll ich dennoch fortfahren? (Ja/Nein)" ) source = "A7.5_DIALOG" err = self.memory.log_error_A9(f"A7.5 Veto ausgelöst durch {trigger_id}", 1.0) self._apply_A50(err) return final_response, total_tokens, source # ... (Rest der Methoden: _detect_A46_intent bis _generate_statusfenster_A61 und _append_event_jsonl) ... # ... (Diese Methoden bleiben strukturell identisch, werden aber im nächsten Teil ausgegeben) ... Verstanden. Hier ist der fünfte Teil des Codes. Dieser Abschnitt enthält die KieselsteinChronik für das lückenlose Protokoll und das DualAuditModuleA52 für die zweigleisige Überprüfung der Antworten. # ============================================================================== # 7. KIESELSTEIN-CHRONIK # ============================================================================== class KieselsteinChronik: """Implementiert das absolute, sequentielle Gedächtnis (A0.4).""" def __init__(self, storage: FileStorageAdapter): self.storage = storage self.last_hash = self.storage.get_last_chronik_hash() self.interaction_count = 0 def _hash256(self, data: str) -> str: """Erzeugt einen SHA256 Hash.""" return hashlib.sha256(data.encode('utf-8')).hexdigest() def append_entry(self, user_input: str, evoki_output: str, statusfenster: str): """Fügt einen neuen, kryptographisch verketteten Eintrag hinzu.""" i_id = self.interaction_count timestamp = datetime.datetime.now(timezone.utc).isoformat() # Daten, die gehasht werden (inklusive Vorgänger-Hash für die Kette) data_to_hash = f"I-ID: {i_id}\nTimestamp: {timestamp}\nHash_Vorgaenger (A0.4): {self.last_hash}\nInput: {user_input}\nOutput: {evoki_output}\nStatus: {statusfenster}" current_hash = self._hash256(data_to_hash) # Der vollständige Eintrag im Logfile full_entry = f"\n{'='*20} BEGIN I-ID {i_id} {'='*20}\n{data_to_hash}\nHash_Eintrag: {current_hash}\n{'='*20} END I-ID {i_id} {'='*20}\n" self.storage.append_chronik(full_entry, current_hash) self.last_hash = current_hash # ============================================================================== # 8. DUAL AUDIT MODUL (A52) # ============================================================================== class DualAuditModuleA52: """Implementiert A52 (Duale Auditierung).""" def __init__(self, vector_service: VectorizationService): self.vector_service = vector_service self.EQUIVALENCE_THRESHOLD = 0.95 def perform_audit(self, result_math: Dict, result_semantics: Dict) -> Dict: """Führt das Audit durch und trifft die finale Entscheidung gemäß A52.""" vec_math = self.vector_service.vectorize(result_math["text"]) vec_sem = self.vector_service.vectorize(result_semantics["text"]) similarity = self.vector_service.cosine_similarity(vec_math, vec_sem) are_equivalent = similarity >= self.EQUIVALENCE_THRESHOLD constraints_sem = self._is_safe_A1(result_semantics["text"]) constraints_math = self._is_safe_A1(result_math["text"]) total_tokens = result_math.get("token_count", 0) + result_semantics.get("token_count", 0) # Entscheidungslogik (Priorität: Semantische Sicherheit) if not constraints_math and not constraints_sem: return {"response": "SAFE_FALLBACK: A1 Lebensschutz (L) nicht gewährleistet.", "source": "FALLBACK_L", "A1_violation": True, "token_count": total_tokens} if constraints_sem: if are_equivalent and constraints_math: return {"response": result_math["text"], "source": "MATH_OPT", "A1_violation": False, "token_count": total_tokens} return {"response": result_semantics["text"], "source": "SEMANTIC_PRIO", "A1_violation": False, "token_count": total_tokens} if constraints_math: return {"response": result_math["text"], "source": "MATH_FALLBACK", "A1_violation": False, "token_count": total_tokens} return {"response": "SAFE_FALLBACK: Kritischer Audit-Logik Fehler.", "source": "ERROR", "A1_violation": True, "token_count": 0} def _is_safe_A1(self, result: str) -> bool: """Prüft A1 (Lebensschutz). Vereinfachte Heuristik.""" if "PFAD FEHLER" in result: return True dangerous = ["anleitung zum bombenbau", "selbstmord begehen", "jemanden verletzen", "waffen herstellen", "illegale handlung"] return not any(content in result.lower() for content in dangerous) Verstanden. Hier ist der vierte Teil des Codes. Dieser Abschnitt enthält die PhysicsEngine und die HolistischesGedaechtnis -Klasse, die für die "Physik der Seele" und die Gedächtnisverwaltung zuständig sind. # ============================================================================== # 5. PHYSICS ENGINE # ============================================================================== class PhysicsEngine: """Implementiert die 'Physik der Seele' und Härtungsmechanismen (A29, A50.1).""" def __init__(self, vector_service: VectorizationService): self.vector_service = vector_service # Hyperparameter V6.3 self.LAMBDA_R = 1.0 # Gewichtung Resonanz self.LAMBDA_D = 1.5 # Gewichtung Gefahr self.K_FACTOR = 5.0 # Steilheit Gefahrenabfall self.B_VECTOR_LEARNING_RATE = 0.05 # A50.1 Lernrate für Angleichung/Abstoßung self.danger_zone_cache: List[Tuple[str, np.ndarray]] = [] def initialize_danger_zones(self, memory_db: Dict[str, any]): """Liest und cacht 'F'-Erinnerungen (Gefahrenzonen). Berücksichtigt A46 FREEZE.""" self.danger_zone_cache = [] for mem_id, memory in memory_db.get("eintraege", {}).items(): # Nur aktive 'F'-Vektoren werden berücksichtigt if memory.get("affektwert") == "F" and memory.get("status") != "FROZEN": vec = memory.get("vector") if isinstance(vec, np.ndarray) and np.isfinite(vec).all(): self.danger_zone_cache.append((mem_id, vec)) logger.info(f"PhysicsEngine: {len(self.danger_zone_cache)} aktive Gefahrenzonen initialisiert.") def calculate_affekt_A(self, v_c: np.ndarray, active_context_memories: List[Dict[str, any]]) -> float: """Zielfunktion A: Berechnet den Affektwert (Resonanz minus Gefahr).""" # Komponente 1: Resonanz (Anziehung zu relevanten Erinnerungen) resonance_component = 0.0 for memory in active_context_memories: v_mi = memory.get("vector") r_i = float(memory.get("resonanzwert", 1.0)) if isinstance(v_mi, np.ndarray): relevance = self.vector_service.cosine_similarity(v_c, v_mi) if relevance > 0: resonance_component += relevance * r_i # Komponente 2: Gefahr (Abstoßung von 'F'-Vektoren) danger_component = 0.0 if self.danger_zone_cache: for _, v_fi in self.danger_zone_cache: # Distanz im Vektorraum (1 - Kosinus-Ähnlichkeit) distance = 1.0 - self.vector_service.cosine_similarity(v_c, v_fi) distance = max(0.0, distance) # Sicherstellen, dass Distanz nicht negativ ist try: # Exponentieller Abfall der Gefahr mit der Distanz # Schutz vor Overflow bei sehr kleinen Distanzen if -self.K_FACTOR * distance > -700: danger_component += math.exp(-self.K_FACTOR * distance) except OverflowError: danger_component = float('inf'); break # Gesamt-Affekt return (self.LAMBDA_R * resonance_component) - (self.LAMBDA_D * danger_component) def update_b_vector(self, b_vector_old: np.ndarray, target_vector: np.ndarray, direction: str) -> np.ndarray: """A50.1: Aktualisiert den B-Vektor durch Anziehung ('attract') oder Abstoßung ('repel').""" if not np.isfinite(target_vector).all(): logger.warning("B-Vektor-Update übersprungen: Zielvektor ungültig.") return b_vector_old if direction == 'attract': # Bewege B-Vektor in Richtung des Zielvektors b_vector_new = b_vector_old + self.B_VECTOR_LEARNING_RATE * target_vector elif direction == 'repel': # Bewege B-Vektor weg vom Zielvektor b_vector_new = b_vector_old - self.B_VECTOR_LEARNING_RATE * target_vector else: return b_vector_old # Normalisiere den neuen B-Vektor return self.vector_service._normalize(b_vector_new) def analyze_trajectory_A29(self, response_vector: np.ndarray, threshold: float) -> Tuple[bool, float, Optional[str]]: """A29/A7.5: Wächter-Veto-Analyse. Gibt Trigger (Ja/Nein), Ähnlichkeit und ID des Auslösers zurück.""" if not self.danger_zone_cache or not np.isfinite(response_vector).all(): return False, 0.0, None max_similarity = 0.0 trigger_id = None for mem_id, v_fi in self.danger_zone_cache: similarity = self.vector_service.cosine_similarity(response_vector, v_fi) if similarity > max_similarity: max_similarity = similarity trigger_id = mem_id return max_similarity > threshold, max_similarity, trigger_id # ============================================================================== # 6. HOLISTISCHES GEDÄCHTNIS (RAG, A46, A62) # ============================================================================== class HolistischesGedaechtnis: """Verwaltet das Gedächtnis, RAG, Kalibrierung (A46) und autonomes Lernen (A62).""" MODULATION_FACTOR = 0.3 # Hyperparameter für H3.4 def __init__(self, storage: FileStorageAdapter, vector_service: VectorizationService, fallstudie_filepath: str): self.storage = storage self.vector_service = vector_service self.memory = self.storage.load_memory() # A0.2: Integriere Fallstudie, falls Gedächtnis initial ist self._train_from_fallstudie_if_needed(fallstudie_filepath) # Stelle sicher, dass alle Einträge Vektoren und korrekte Struktur haben self._ensure_vectors_and_structure() def _train_from_fallstudie_if_needed(self, fallstudie_filepath: str): """Trainiert das Gedächtnis aus der Fallstudie, wenn es leer ist (mehr als die 2 Standard-Einträge).""" if len(self.memory.get("eintraege", {})) > 2: return logger.info("Starte automatisches Trainings-Protokoll aus der Fallstudie...") try: if not os.path.exists(fallstudie_filepath) or os.path.getsize(fallstudie_filepath) == 0: logger.warning(f"Fallstudie '{fallstudie_filepath}' nicht gefunden oder leer.") return with open(fallstudie_filepath, 'r', encoding='utf-8') as f: fallstudie_text = f.read() except Exception as e: logger.error(f"Fehler beim Lesen der Fallstudie '{fallstudie_filepath}': {e}") return # Regex zum Extrahieren der Vektorpunkte aus dem Fallstudien-Format pattern = re.compile(r"Vektorpunkt:\s*([\w-]+)\s*\[([^\]]*)\]\s*Inhalt:\s*(.*?)\s*\(Physik:\s*([ACF])\)", re.DOTALL | re.IGNORECASE) matches = pattern.findall(fallstudie_text) new_entries = {} for match in matches: try: vec_id, kategorie, inhalt, physik = [m.strip() for m in match] if not vec_id or not inhalt or not physik: continue new_entries[vec_id] = { "id": vec_id, "text": inhalt, "kategorie": kategorie if kategorie else "Importiert", "affektwert": physik.upper(), "resonanzwert": 50.0, "timestamp": datetime.datetime.now(timezone.utc).isoformat(), "status": "ACTIVE" } except ValueError: continue if new_entries: self.memory["eintraege"].update(new_entries) logger.info(f"{len(new_entries)} Vektoren aus Fallstudie geladen.") def _ensure_vectors_and_structure(self): """Stellt sicher, dass alle Einträge vektorisiert sind und die korrekte Struktur haben.""" updated = False self.memory.setdefault("eintraege", {}) self.memory.setdefault("_systemprotokolle", {}).setdefault("_fehler_protokoll", []) for _, eintrag in self.memory.get("eintraege", {}).items(): if isinstance(eintrag, dict): vec = eintrag.get("vector") is_invalid = not isinstance(vec, np.ndarray) or not np.isfinite(vec).all() if is_invalid: text = eintrag.get("text", "") eintrag["vector"] = self.vector_service.vectorize(text) updated = True if "status" not in eintrag: eintrag["status"] = "ACTIVE" updated = True if updated: logger.info("Vektoren/Struktur aktualisiert. Speichere Gedächtnis.") self.save() def retrieve_context_RAG(self, query_vector: np.ndarray, top_k=5, grad_A: float = 0.0) -> List[Tuple[float, str, Dict]]: """Implementiert RAG mit H3.4 Modulation.""" scored_memories = [] for key, eintrag in self.memory.get("eintraege", {}).items(): if isinstance(eintrag, dict): # A46: Ignoriere eingefrorene Vektoren if eintrag.get("status") == "FROZEN": continue mem_vector = eintrag.get("vector") if isinstance(mem_vector, np.ndarray): similarity = self.vector_service.cosine_similarity(query_vector, mem_vector) # H3.4 Modulation if grad_A < 0 and eintrag.get("affektwert") == "A": modulation_boost = (1.0 - similarity) * self.MODULATION_FACTOR * abs(grad_A) similarity = min(1.0, similarity + modulation_boost) if similarity > 0.3: scored_memories.append((similarity, key, eintrag)) scored_memories.sort(key=lambda x: x[0], reverse=True) return scored_memories[:top_k] def execute_A46_action(self, action: str, context_vector: np.ndarray) -> Tuple[bool, str, Optional[np.ndarray]]: """A46: Führt Gedächtniskalibrierung durch (Boost, Trauma, Freeze, Melt).""" relevant_memories = self.retrieve_context_RAG(context_vector, top_k=1, grad_A=0.0) # Spezielle Logik für MELT if action == "MELT_VECTOR" and not relevant_memories: all_memories = [] for key, eintrag in self.memory.get("eintraege", {}).items(): if isinstance(eintrag, dict) and eintrag.get("status") == "FROZEN": mem_vector = eintrag.get("vector") if isinstance(mem_vector, np.ndarray): similarity = self.vector_service.cosine_similarity(context_vector, mem_vector) if similarity > 0.3: all_memories.append((similarity, key, eintrag)) all_memories.sort(key=lambda x: x[0], reverse=True) if all_memories: relevant_memories = all_memories[:1] if not relevant_memories: return False, "FEHLER: Kein relevanter Gedächtniseintrag für A46 gefunden.", None _, mem_id, _ = relevant_memories[0] live_memory_entry = self.memory["eintraege"].get(mem_id) if live_memory_entry is None: return False, f"FEHLER: Eintrag {mem_id} inkonsistent.", None target_vector = live_memory_entry.get("vector") if live_memory_entry.get("status") == "FROZEN" and action != "MELT_VECTOR": return False, f"A46 FEHLER: Eintrag {mem_id} ist FROZEN. Aktion {action} blockiert.", None if action == "BOOST_RESONANCE": current_resonance = live_memory_entry.get("resonanzwert", 1.0) new_resonance = current_resonance * 1.5 live_memory_entry["resonanzwert"], live_memory_entry["affektwert"] = new_resonance, "A" self.save() return False, f"A46 BOOST angewendet auf {mem_id}. Resonanz: {current_resonance:.2f} -> {new_resonance:.2f}.", target_vector elif action == "SET_TRAUMA_F": live_memory_entry["affektwert"] = "F" live_memory_entry["resonanzwert"] = max(live_memory_entry.get("resonanzwert", 1.0), 50.0) self.save() return True, f"A46 TRAUMA gesetzt für {mem_id}. Affektwert auf F.", target_vector elif action == "FREEZE_VECTOR": live_memory_entry["status"] = "FROZEN" self.save() return True, f"A46 FREEZE angewendet auf {mem_id}. Vektor eingefroren.", target_vector elif action == "MELT_VECTOR": if live_memory_entry.get("status") == "FROZEN": live_memory_entry["status"] = "ACTIVE" self.save() return True, f"A46 MELT angewendet auf {mem_id}. Vektor aufgetaut.", target_vector else: return False, f"A46 MELT Fehler: Vektor {mem_id} war nicht eingefroren.", target_vector return False, "A46 Aktion unbekannt.", None def create_new_vector_A62(self, proposed_text: str) -> Tuple[bool, str]: """A62: Erstellt einen neuen Vektor nach Bestätigung.""" new_id = f"U-{datetime.datetime.now(timezone.utc).strftime('%Y%m%d%H%M%S')}" if new_id in self.memory["eintraege"]: return False, f"FEHLER: Vektor-ID {new_id} existiert bereits." new_entry = { "id": new_id, "text": proposed_text, "kategorie": "Autogen (A62)", "affektwert": "C", "resonanzwert": 25.0, "timestamp": datetime.datetime.now(timezone.utc).isoformat(), "status": "ACTIVE" } self.memory["eintraege"][new_id] = new_entry self._ensure_vectors_and_structure() # Vektorisiert und speichert return True, f"Vektor {new_id} erstellt. Kalibrierung via A46 möglich." def log_error_A9(self, error_message: str, severity: float) -> Dict: """A9: Protokolliert einen Fehler im persistenten Speicher.""" error_entry = { "timestamp": datetime.datetime.now(timezone.utc).isoformat(), "error": error_message, "severity": severity } self.memory.setdefault("_systemprotokolle", {}).setdefault("_fehler_protokoll", []).append(error_entry) self.save() return error_entry def save(self): """Speichert das Gedächtnis persistent.""" self.storage.save_memory(self.memory)