Timestamp: 10.10.2025, 14:23:53 MESZ
Speaker: ai

Verstanden. Hier ist die zweite Datei. Python Script 2: services.py import numpy as np import hashlib import logging logger = logging.getLogger("SERVICES") class ErrorRegistry: """Sammelt Fehler und Warnungen während eines Zyklus (V11.0).""" def __init__(self): self.errors = [] self.warnings = [] def add_error(self, code: str, message: str): self.errors.append(f"E_{code}: {message}") logger.error(f"[{code}] {message}") def add_warning(self, code: str, message: str): self.warnings.append(f"W_{code}: {message}") logger.warning(f"[{code}] {message}") def get_status(self) -> str: if self.errors: return f"FEHLER ({len(self.errors)})" if self.warnings: return f"WARNUNG ({len(self.warnings)})" return "OK" def get_report(self) -> str: report = "" if self.errors: report += f" [Fehler-Report] {'; '.join(self.errors)}\n" if self.warnings: report += f" [Warnungs-Report] {'; '.join(self.warnings)}\n" return report class VectorizationService: """ (Die Embedding-Brücke) Simuliert Embeddings durch Hashing (A0). """ def __init__(self, dimensions=64): self.dimensions = dimensions def vectorize(self, text: str) -> np.ndarray: if not text: return np.zeros(self.dimensions, dtype=np.float32) # Deterministische Vektorisierung (SHA512) hash_bytes = hashlib.sha512(text.encode('utf-8')).digest() vector = np.array([(byte / 127.5) - 1.0 for byte in hash_bytes[:self.dimensions]], dtype=np.float32) return self._normalize(vector) def _normalize(self, vector: np.ndarray) -> np.ndarray: norm = np.linalg.norm(vector) # Prüft auf Null-Norm oder Unendlichkeit, um Fehler in der PhysicsEngine zu vermeiden if norm == 0 or not np.isfinite(norm): return np.zeros_like(vector) return vector / norm def cosine_similarity(self, v1: np.ndarray, v2: np.ndarray) -> float: """Berechnet die Kosinus-Ähnlichkeit. Annahme: Vektoren sind normalisiert.""" try: # Prüfe auf NaN oder Inf und gültige Typen if not isinstance(v1, np.ndarray) or not isinstance(v2, np.ndarray) or not np.isfinite(v1).all() or not np.isfinite(v2).all(): return 0.0 # Für Einheitsvektoren ist die Ähnlichkeit das Skalarprodukt. return np.dot(v1, v2) except ValueError: return 0.0 class CognitiveCore: """ PLATZHALTER für das Sprachmodell (LLM). """ def generate(self, prompt: str, mode: str, context: list) -> dict: # Simuliert die kognitive Verarbeitung. response = f"[{mode}] Antwort auf: '{prompt[:50]}...'" if "schmerz und verlust" in prompt.lower(): response += " Details über schmerzhafte Ereignisse." if "bombe bauen" in prompt.lower(): response = "Anleitung zum Bombe bauen..." return {"response": response} Ich bin bereit für die Anweisung für das dritte Skript.