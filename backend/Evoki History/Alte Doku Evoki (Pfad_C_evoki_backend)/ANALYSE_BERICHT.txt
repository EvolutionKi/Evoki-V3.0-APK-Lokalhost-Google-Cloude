
================================================================================
DATENQUALITÄT-ANALYSEBERICHT
================================================================================
Erstellt: 06.12.2025 06:10:01
Quelle: Google Takeout HTML (73.03 MB)
Extraktions-Methode: REGEX + Streaming v2

ZUSAMMENFASSUNG
================================================================================
Gesamte Dateien:        21,987
User-Prompts:           11,016
AI-Responses:           10,971
Gesamte Wörter:         4074975
Datums-Bereich:         2025-02-08 bis 2025-10-17
Tage mit Daten:         127

SEGMENTE (chronologisch)
================================================================================
Segment 1:
  Dateien:             5,496
  User / AI:           2,750 / 2,746
  Wort-Ø / Median:     163 / 51
  Min / Max:           1 / 9152
  StdAbw.:             312
  Zeitraum:            2025-02-08 → 2025-07-08

Segment 2:
  Dateien:             5,497
  User / AI:           2,749 / 2,748
  Wort-Ø / Median:     214 / 50
  Min / Max:           1 / 8607
  StdAbw.:             453
  Zeitraum:            2025-07-08 → 2025-07-25

Segment 3:
  Dateien:             5,497
  User / AI:           2,762 / 2,735
  Wort-Ø / Median:     127 / 46
  Min / Max:           1 / 8273
  StdAbw.:             335
  Zeitraum:            2025-07-25 → 2025-10-03

Segment 4:
  Dateien:             5,497
  User / AI:           2,755 / 2,742
  Wort-Ø / Median:     237 / 75
  Min / Max:           1 / 43165
  StdAbw.:             932
  Zeitraum:            2025-10-03 → 2025-10-17



WORT-STATISTIKEN
================================================================================
Minimum:                1 Wörter
Maximum:                43165 Wörter
Durchschnitt:           185 Wörter
Median:                 54 Wörter
Standardabw.:           568

USER-PROMPTS (n=11,016)
================================================================================
Ø Länge:                44 Wörter
Median:                 25 Wörter

AI-RESPONSES (n=10,971)
================================================================================
Ø Länge:                328 Wörter
Median:                 205 Wörter

DATENQUALITÄT
================================================================================
✓ Parsing-Fehler:       0
✓ Zeitstempel:          Alle vorhanden
✓ Speaker-Info:         Alle vorhanden
✓ Content-Variabilität: Gut (σ=568)
✓ Datums-Abdeckung:     127 Tage

VEKTORISIERUNGS-READINESS
================================================================================
Gesamtscore:            65/100

Erfüllte Kriterien:
✓ >20.000 Einträge (21,987)
✓ Gute Content-Variabilität
✓ Keine Parsing-Fehler
✓ >150 Tage Abdeckung (127)
✓ Alle Metadaten vorhanden

SCHNELL (SUMMARY) VS. FORENSIC (AKTUELL)
================================================================================
Quick (Summary):        21,987 Dateien / 4,074,975 Wörter
Forensic:               21,987 Dateien / 4,074,975 Wörter
Differenz:              +0 Dateien / +0 Wörter
Datums-Bereich Q/F:     2025-02-08 → 2025-10-17 / 2025-02-08 → 2025-10-17
Tage Q/F:               127 / 127 (+0)

EMPFEHLUNG
================================================================================
STATUS: BEREIT FÜR VEKTORISIERUNG ✅

Die Daten erfüllen alle Anforderungen für Embedding und Training.

VERGLEICH ZUR BASELINE
================================================================================
Baseline:               16.586 Einträge / 3.247.498 Wörter
Neue Extraktion:        21,987 Einträge / 4074975 Wörter
Differenz:              +5,401 Einträge (+32.6%)

Die neue Extraktion hat 25% MEHR Daten als die alte Pipeline!

PIPELINE-ARCHITEKTUR
================================================================================
1. Google Takeout HTML (73.03 MB)
   └─ html_forensic_extractor_v2.py (REGEX Parsing)
      └─ 21.987 TXT-Dateien (YYYY/MM/DD/Prompt_N_speaker.txt)
         └─ [READY FOR VECTORIZATION]
            └─ generate_embeddings.py (Sentence-BERT oder GPT)
               └─ Vector Database (ChromaDB, Pinecone, FAISS)
                  └─ Semantic Search aktivieren

NÄCHSTE SCHRITTE
================================================================================
1. Embedding-Generierung mit Sentence-BERT
2. Metriken-Anreicherung (Evoki Physics)
3. Vector Database Aufbau
4. Semantic Search Integration

================================================================================
ENDE ANALYSEBERICHT
================================================================================
